# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from core.column_matcher import ColumnMatcher
from core.db_manager import DBManager
from utils.file_handler import FileHandler
from datetime import datetime
from io import BytesIO


def render():
    st.title('å ±è¡¨åˆä½µå™¨')
    st.markdown('æ•´åˆå¤šä»½æ¬„ä½ä¸çµ±ä¸€çš„å ±è¡¨ï¼Œæ™ºæ…§å°é½Šæ¬„ä½')

    # åˆå§‹åŒ–ç¯„æœ¬è³‡æ–™åº«
    template_db = DBManager('workflow_templates')

    # ========== ç¯„æœ¬ç®¡ç†å€ ==========
    st.divider()
    with st.expander('ğŸ“ æµç¨‹ç¯„æœ¬ç®¡ç†', expanded=False):
        tab_new, tab_load, tab_manage = st.tabs(['æ–°å»ºæµç¨‹', 'è¼‰å…¥ç¯„æœ¬', 'ç®¡ç†ç¯„æœ¬'])

        with tab_new:
            st.info('é¸æ“‡æ­¤é¸é …ä»¥å»ºç«‹æ–°çš„åˆä½µæµç¨‹ï¼ˆä¸ä½¿ç”¨ç¯„æœ¬ï¼‰')

        with tab_load:
            templates = template_db.get_all_templates('M1')
            if templates:
                st.write(f'æ‰¾åˆ° {len(templates)} å€‹å·²å„²å­˜çš„ç¯„æœ¬ï¼š')

                # é¡¯ç¤ºç¯„æœ¬åˆ—è¡¨
                for template in templates:
                    with st.expander(f"ğŸ“„ {template['template_name']}", expanded=False):
                        st.caption(f"èªªæ˜ï¼š{template.get('description', 'ç„¡èªªæ˜')}")
                        st.caption(f"å»ºç«‹æ™‚é–“ï¼š{template['created_at']}")
                        st.caption(f"æ›´æ–°æ™‚é–“ï¼š{template['updated_at']}")

                        if st.button(f'è¼‰å…¥æ­¤ç¯„æœ¬', key=f"load_{template['template_name']}"):
                            # è¼‰å…¥å®Œæ•´ç¯„æœ¬è³‡æ–™
                            full_template = template_db.load_template('M1', template['template_name'])
                            if full_template:
                                st.session_state.loaded_template = full_template
                                st.success(f"âœ… å·²è¼‰å…¥ç¯„æœ¬ã€Œ{template['template_name']}ã€")
                                st.info('â¬‡ï¸ è«‹å‘ä¸‹æ»¾å‹•è‡³ã€Œæ­¥é©Ÿ 1ã€ä¸Šå‚³æª”æ¡ˆï¼Œç³»çµ±å°‡è‡ªå‹•å¥—ç”¨ç¯„æœ¬è¨­å®š')
                                st.rerun()
            else:
                st.info('ç›®å‰æ²’æœ‰å·²å„²å­˜çš„ç¯„æœ¬')

        with tab_manage:
            templates = template_db.get_all_templates('M1')
            if templates:
                st.write(f'ç®¡ç† {len(templates)} å€‹ç¯„æœ¬ï¼š')

                for template in templates:
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.write(f"ğŸ“„ **{template['template_name']}**")
                        st.caption(template.get('description', 'ç„¡èªªæ˜'))
                    with col2:
                        if st.button('ğŸ—‘ï¸', key=f"del_{template['template_name']}", help='åˆªé™¤æ­¤ç¯„æœ¬'):
                            result = template_db.delete_template('M1', template['template_name'])
                            if result['success']:
                                st.success(result['message'])
                                st.rerun()
                            else:
                                st.error(result['message'])
            else:
                st.info('ç›®å‰æ²’æœ‰ç¯„æœ¬å¯ç®¡ç†')

    st.divider()
    st.subheader('æ­¥é©Ÿ 1: ä¸Šå‚³å ±è¡¨æª”æ¡ˆ')
    uploaded_files = st.file_uploader(
        'ä¸Šå‚³ Excel æˆ– CSV æª”æ¡ˆ (å¯å¤šé¸)',
        type=['xlsx', 'xls', 'csv'],
        accept_multiple_files=True,
        key='file_uploader'
    )

    if not uploaded_files:
        st.info('ğŸ“‚ è«‹ä¸Šå‚³è‡³å°‘ä¸€å€‹æª”æ¡ˆé–‹å§‹ä½¿ç”¨')
        return

    # è¼‰å…¥æª”æ¡ˆï¼ˆæ¯æ¬¡éƒ½é‡æ–°è¼‰å…¥ï¼Œä¸ä¿å­˜ï¼‰
    try:
        dataframes = {}
        for file in uploaded_files:
            df = FileHandler.load_file(file)
            dataframes[file.name] = df
    except Exception as e:
        st.error(f'è¼‰å…¥æª”æ¡ˆå¤±æ•—: {e}')
        return

    st.success(f'å·²è¼‰å…¥ {len(dataframes)} å€‹æª”æ¡ˆ')

    # é¡¯ç¤ºæª”æ¡ˆé è¦½
    for filename, df in dataframes.items():
        with st.expander(f'ğŸ“„ {filename}'):
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric('è³‡æ–™ç­†æ•¸', df.shape[0])
                st.metric('æ¬„ä½æ•¸é‡', df.shape[1])
            with col2:
                st.write('**æ¬„ä½åˆ—è¡¨:**')
                st.code(', '.join(df.columns.tolist()))
            st.write('**è³‡æ–™é è¦½:**')
            st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
            st.dataframe(df, width='stretch')

    # æª¢æŸ¥æ˜¯å¦æœ‰è¼‰å…¥çš„ç¯„æœ¬
    has_template = 'loaded_template' in st.session_state and st.session_state.loaded_template is not None

    if has_template:
        template_info = st.session_state.loaded_template
        st.info(f"ğŸ“ å·²è¼‰å…¥ç¯„æœ¬ï¼š**{template_info['template_name']}** | {template_info.get('description', '')}")

    st.divider()
    st.subheader('æ­¥é©Ÿ 2: æ™ºæ…§æ¬„ä½å°é½Š')

    # æ”¶é›†æ‰€æœ‰æ¬„ä½
    all_columns = {}
    for filename, df in dataframes.items():
        for col in df.columns:
            if col not in all_columns:
                all_columns[col] = []
            all_columns[col].append(filename)

    # å¦‚æœæœ‰ç¯„æœ¬ï¼Œç›´æ¥ä½¿ç”¨ç¯„æœ¬çš„æ¬„ä½å°æ‡‰
    if has_template:
        template_config = template_info['config']
        unified_mapping_from_template = template_config.get('column_mapping', {})

        st.success('âœ… ä½¿ç”¨ç¯„æœ¬çš„æ¬„ä½å°æ‡‰è¨­å®š')
        st.write('**ç¯„æœ¬è¨­å®šçš„æ¬„ä½å°æ‡‰ï¼š**')

        # é¡¯ç¤ºç¯„æœ¬çš„æ¬„ä½å°æ‡‰
        mapping_display = {}
        for orig_col, unified_col in unified_mapping_from_template.items():
            if unified_col not in mapping_display:
                mapping_display[unified_col] = []
            mapping_display[unified_col].append(orig_col)

        for unified_col, orig_cols in mapping_display.items():
            st.write(f"- **{unified_col}** â† {', '.join(orig_cols)}")

        # ç›´æ¥è·³åˆ°æ­¥é©Ÿ 3
        unified_mapping = unified_mapping_from_template
        column_groups = {}  # ä¸éœ€è¦ç”¨æˆ¶è¨­å®š

    else:
        # åŸæœ‰çš„æ™ºæ…§æ¬„ä½å°é½Šé‚è¼¯
        # æ‰¾å‡ºç›¸ä¼¼æ¬„ä½
        from difflib import SequenceMatcher
        column_groups = {}
        all_col_list = list(all_columns.keys())
        processed = set()

        for col in all_col_list:
            if col in processed:
                continue

            group = [col]
            for other_col in all_col_list:
                if other_col != col and other_col not in processed:
                    similarity = SequenceMatcher(None, col.lower(), other_col.lower()).ratio()
                    if similarity >= 0.6:
                        group.append(other_col)
                        processed.add(other_col)

            processed.add(col)
            standard_name = min(group, key=len) if len(group) > 1 else col
            column_groups[standard_name] = group

        st.write('**ç³»çµ±è‡ªå‹•è­˜åˆ¥çš„æ¬„ä½å°æ‡‰é—œä¿‚ï¼š**')
        st.info('è«‹ç¢ºèªä»¥ä¸‹æ¬„ä½å°æ‡‰æ˜¯å¦æ­£ç¢ºï¼Œæ‚¨å¯ä»¥ä¿®æ”¹ã€Œçµ±ä¸€æ¬„ä½åç¨±ã€')

        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„æ¬„ä½åç¨±ï¼ˆç”¨æ–¼ä¸‹æ‹‰é¸å–®ï¼‰
        all_unique_cols = sorted(set(all_columns.keys()))

        # é¡¯ç¤ºæ¬„ä½ç¾¤çµ„ä¸¦æ”¶é›†ç”¨æˆ¶è¼¸å…¥
        group_idx = 0
        for standard_name, similar_cols in column_groups.items():
            if len(similar_cols) > 1:
                with st.expander(f'ğŸ”— æ¬„ä½ç¾¤çµ„ {group_idx + 1}: {", ".join(similar_cols)}', expanded=True):
                    st.write(f'**è­˜åˆ¥åˆ°çš„ç›¸ä¼¼æ¬„ä½:** {", ".join(similar_cols)}')

                    for col in similar_cols:
                        st.caption(f'  â€¢ `{col}` ä¾†è‡ª: {", ".join(all_columns[col])}')

                    st.text_input(
                        'çµ±ä¸€æ¬„ä½åç¨±',
                        value=standard_name,
                        key=f'unified_name_{group_idx}'
                    )
                group_idx += 1
            else:
                # é¡¯ç¤ºå–®ç¨æ¬„ä½ï¼Œè®“ç”¨æˆ¶å¯ä»¥é¸æ“‡å°æ‡‰åˆ°å“ªå€‹æ¬„ä½
                col_name = similar_cols[0]
                with st.expander(f'ğŸ“Œ å–®ç¨æ¬„ä½: {col_name}', expanded=False):
                    st.caption(f'ä¾†è‡ª: {", ".join(all_columns[col_name])}')

                    # æä¾›é¸é …ï¼šä¿æŒåŸæ¨£æˆ–å°æ‡‰åˆ°å…¶ä»–æ¬„ä½
                    map_option = st.radio(
                        'è™•ç†æ–¹å¼',
                        ['ä¿æŒåŸæ¬„ä½åç¨±', 'å°æ‡‰åˆ°å…¶ä»–æ¬„ä½'],
                        key=f'map_option_{group_idx}'
                    )

                    if map_option == 'å°æ‡‰åˆ°å…¶ä»–æ¬„ä½':
                        st.selectbox(
                            'å°æ‡‰åˆ°',
                            options=all_unique_cols,
                            key=f'unified_name_{group_idx}'
                        )
                    else:
                        # ä½¿ç”¨éš±è—çš„æ–¹å¼å„²å­˜åŸæ¬„ä½åç¨±
                        if f'unified_name_{group_idx}' not in st.session_state:
                            st.session_state[f'unified_name_{group_idx}'] = col_name
                group_idx += 1

    st.divider()
    st.subheader('æ­¥é©Ÿ 3: é¸æ“‡åˆä½µæ–¹å¼')

    # å¦‚æœæ²’æœ‰ç¯„æœ¬ï¼Œéœ€è¦å»ºç«‹ unified_mapping_preview
    if not has_template:
        # é å…ˆå»ºç«‹ unified_mappingï¼ˆç”¨æ–¼é¡¯ç¤ºåˆä½µéµé¸é …ï¼‰
        unified_mapping_preview = {}
        group_idx = 0
        for standard_name, similar_cols in column_groups.items():
            if len(similar_cols) > 1:
                unified_name = st.session_state.get(f'unified_name_{group_idx}', standard_name)
            else:
                map_option = st.session_state.get(f'map_option_{group_idx}', 'ä¿æŒåŸæ¬„ä½åç¨±')
                if map_option == 'å°æ‡‰åˆ°å…¶ä»–æ¬„ä½':
                    unified_name = st.session_state.get(f'unified_name_{group_idx}', standard_name)
                else:
                    unified_name = standard_name
            group_idx += 1
            for col in similar_cols:
                unified_mapping_preview[col] = unified_name
    else:
        # ä½¿ç”¨ç¯„æœ¬çš„æ¬„ä½å°æ‡‰
        unified_mapping_preview = unified_mapping

    # å¾ç¯„æœ¬å–å¾—é è¨­å€¼ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
    template_merge_method = None
    template_merge_key = None
    template_merge_how = None
    template_remove_dup = True

    if has_template:
        template_config = template_info['config']
        template_merge_method = template_config.get('merge_method', 'å‚ç›´å †ç–Š')
        template_merge_key = template_config.get('merge_key')
        template_merge_how = template_config.get('merge_how', 'outer')
        template_remove_dup = template_config.get('remove_duplicates', True)

    col1, col2 = st.columns(2)
    with col1:
        merge_method_index = 0 if template_merge_method == 'å‚ç›´å †ç–Š' else 1 if template_merge_method else 0
        merge_method = st.radio(
            'åˆä½µæ–¹å¼',
            ['å‚ç›´å †ç–Š', 'ä¾ Key åˆä½µ'],
            index=merge_method_index,
            help='å‚ç›´å †ç–Šï¼šå°‡æ‰€æœ‰è³‡æ–™ä¸Šä¸‹ç–ŠåŠ ï½œä¾ Key åˆä½µï¼šæ ¹æ“šå…±åŒæ¬„ä½æ©«å‘åˆä½µ'
        )

    with col2:
        if merge_method == 'ä¾ Key åˆä½µ':
            unified_cols = sorted(set(unified_mapping_preview.values()))
            # å¾ç¯„æœ¬æ‰¾åˆ°é è¨­çš„ merge_key index
            default_key_index = 0
            if template_merge_key and template_merge_key in unified_cols:
                default_key_index = unified_cols.index(template_merge_key)

            merge_key = st.selectbox(
                'é¸æ“‡åˆä½µéµï¼ˆKeyï¼‰',
                options=unified_cols,
                index=default_key_index,
                help='é€šå¸¸é¸æ“‡ã€Œå·¥è™Ÿã€ã€ã€Œå“¡å·¥ç·¨è™Ÿã€ç­‰å”¯ä¸€è­˜åˆ¥æ¬„ä½'
            )

            # å¾ç¯„æœ¬æ‰¾åˆ°é è¨­çš„ merge_how index
            how_options = ['outer', 'inner', 'left']
            default_how_index = 0
            if template_merge_how and template_merge_how in how_options:
                default_how_index = how_options.index(template_merge_how)

            merge_how = st.selectbox(
                'åˆä½µæ–¹å¼',
                options=how_options,
                index=default_how_index,
                format_func=lambda x: {
                    'outer': 'å¤–éƒ¨åˆä½µï¼ˆä¿ç•™æ‰€æœ‰è³‡æ–™ï¼‰',
                    'inner': 'å…§éƒ¨åˆä½µï¼ˆåªä¿ç•™å…±åŒè³‡æ–™ï¼‰',
                    'left': 'å·¦å´åˆä½µï¼ˆä»¥ç¬¬ä¸€å€‹æª”æ¡ˆç‚ºä¸»ï¼‰'
                }[x]
            )
        else:
            merge_key = None
            merge_how = None

    remove_duplicates = st.checkbox('ç§»é™¤é‡è¤‡è³‡æ–™', value=template_remove_dup)

    st.divider()
    st.subheader('æ­¥é©Ÿ 4: åŸ·è¡Œåˆä½µ')

    if st.button('ğŸš€ åŸ·è¡Œåˆä½µ', type='primary', width='stretch'):
        try:
            with st.spinner('æ­£åœ¨åˆä½µè³‡æ–™...'):
                # å»ºç«‹æ¬„ä½å°æ‡‰è¡¨ï¼ˆå¾ session_state è®€å–ç”¨æˆ¶è¼¸å…¥ï¼‰
                unified_mapping = {}
                group_idx = 0
                for standard_name, similar_cols in column_groups.items():
                    if len(similar_cols) > 1:
                        # æœ‰ç›¸ä¼¼æ¬„ä½ç¾¤çµ„ï¼Œå¾ session_state è®€å–ç”¨æˆ¶è¼¸å…¥
                        unified_name = st.session_state.get(f'unified_name_{group_idx}', standard_name)
                    else:
                        # å–®ç¨æ¬„ä½ï¼Œæª¢æŸ¥ç”¨æˆ¶é¸æ“‡çš„è™•ç†æ–¹å¼
                        map_option = st.session_state.get(f'map_option_{group_idx}', 'ä¿æŒåŸæ¬„ä½åç¨±')
                        if map_option == 'å°æ‡‰åˆ°å…¶ä»–æ¬„ä½':
                            unified_name = st.session_state.get(f'unified_name_{group_idx}', standard_name)
                        else:
                            unified_name = standard_name

                    group_idx += 1

                    for col in similar_cols:
                        unified_mapping[col] = unified_name

                # å³æ™‚è™•ç†ï¼šé‡å‘½åä¸¦æ¸…ç†æ‰€æœ‰ DataFrame
                cleaned_dfs = []
                for filename, df in dataframes.items():
                    # å»ºç«‹æ–°çš„æ¬„ä½åç¨±åˆ—è¡¨å’Œå°æ‡‰çš„æ¬„ä½ç´¢å¼•
                    new_columns = []
                    col_positions = []
                    seen = set()

                    for idx, col in enumerate(df.columns):
                        # å–å¾—çµ±ä¸€åç¨±
                        unified_col = unified_mapping.get(col, col)

                        # åªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç¾çš„æ¬„ä½åç¨±
                        if unified_col not in seen:
                            new_columns.append(unified_col)
                            col_positions.append(idx)
                            seen.add(unified_col)

                    # ä½¿ç”¨ iloc æ ¹æ“šä½ç½®ç´¢å¼•é¸æ“‡æ¬„ä½ï¼Œé¿å…åˆ—åé‡è¤‡å•é¡Œ
                    df_clean = df.iloc[:, col_positions].copy()
                    df_clean.columns = new_columns
                    df_clean = df_clean.reset_index(drop=True)

                    cleaned_dfs.append(df_clean)

                # åŸ·è¡Œåˆä½µ
                if merge_method == 'å‚ç›´å †ç–Š':
                    result_df = pd.concat(cleaned_dfs, ignore_index=True, sort=False)

                elif merge_method == 'ä¾ Key åˆä½µ':
                    result_df = cleaned_dfs[0].copy()

                    for df in cleaned_dfs[1:]:
                        if merge_key not in result_df.columns or merge_key not in df.columns:
                            st.error(f'åˆä½µéµã€Œ{merge_key}ã€åœ¨æŸäº›æª”æ¡ˆä¸­ä¸å­˜åœ¨ï¼')
                            st.stop()

                        result_df = pd.merge(
                            result_df,
                            df,
                            on=merge_key,
                            how=merge_how,
                            suffixes=('', '_dup')
                        )

                    # ç§»é™¤é‡è¤‡æ¬„ä½
                    dup_cols = [col for col in result_df.columns if col.endswith('_dup')]
                    if dup_cols:
                        st.info(f'ç§»é™¤é‡è¤‡æ¬„ä½: {", ".join(dup_cols)}')
                        result_df = result_df.drop(columns=dup_cols)

                # ç§»é™¤é‡è¤‡è³‡æ–™
                if remove_duplicates:
                    before_count = len(result_df)
                    result_df = result_df.drop_duplicates(keep='first')
                    after_count = len(result_df)
                    if before_count > after_count:
                        st.info(f'å·²ç§»é™¤ {before_count - after_count} ç­†é‡è¤‡è³‡æ–™')

                st.success(f'âœ… åˆä½µå®Œæˆï¼å…± {len(result_df)} ç­†è³‡æ–™ï¼Œ{len(result_df.columns)} å€‹æ¬„ä½')

                st.write('**åˆä½µçµæœé è¦½:**')
                st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
                st.dataframe(result_df, width='stretch')

                # åŒ¯å‡º Excel
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    result_df.to_excel(writer, index=False, sheet_name='åˆä½µçµæœ')
                output.seek(0)

                st.download_button(
                    label='ğŸ“¥ ä¸‹è¼‰åˆä½µçµæœï¼ˆExcelï¼‰',
                    data=output,
                    file_name=f'merged_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    width='stretch'
                )

                # ========== å„²å­˜ç‚ºç¯„æœ¬ ==========
                st.divider()
                st.subheader('ğŸ’¾ å„²å­˜æ­¤æµç¨‹ç‚ºç¯„æœ¬')
                st.info('å„²å­˜å¾Œï¼Œä¸‹æ¬¡é‡åˆ°ç›¸åŒæ ¼å¼çš„å ±è¡¨æ™‚å¯ä»¥ç›´æ¥å¥—ç”¨ï¼Œç„¡éœ€é‡æ–°è¨­å®š')

                with st.form('save_template_form'):
                    template_name = st.text_input('ç¯„æœ¬åç¨±', placeholder='ä¾‹å¦‚ï¼šæœˆå ±æ•´åˆæµç¨‹')
                    template_desc = st.text_area('ç¯„æœ¬èªªæ˜ï¼ˆé¸å¡«ï¼‰', placeholder='ç°¡çŸ­æè¿°æ­¤ç¯„æœ¬çš„ç”¨é€”')

                    submitted = st.form_submit_button('ğŸ’¾ å„²å­˜ç¯„æœ¬', type='primary')

                    if submitted:
                        if not template_name.strip():
                            st.error('è«‹è¼¸å…¥ç¯„æœ¬åç¨±')
                        else:
                            # å»ºç«‹ç¯„æœ¬è¨­å®š
                            template_config = {
                                'column_mapping': unified_mapping,
                                'merge_method': merge_method,
                                'merge_key': merge_key if merge_method == 'ä¾ Key åˆä½µ' else None,
                                'merge_how': merge_how if merge_method == 'ä¾ Key åˆä½µ' else None,
                                'remove_duplicates': remove_duplicates
                            }

                            result = template_db.save_template(
                                module='M1',
                                template_name=template_name.strip(),
                                config=template_config,
                                description=template_desc.strip() if template_desc.strip() else None
                            )

                            if result['success']:
                                st.success(result['message'])
                                st.balloons()
                            else:
                                st.error(result['message'])

        except Exception as e:
            st.error(f'åˆä½µå¤±æ•—: {str(e)}')
            import traceback
            st.code(traceback.format_exc())
