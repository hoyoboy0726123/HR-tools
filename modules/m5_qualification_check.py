"""
æ¨¡çµ„5: è³‡æ ¼æª¢æ ¸å™¨ (Qualification Checker)
é›¢è·å›ä»»è³‡æ ¼æª¢æ ¸ç³»çµ±

è¨­è¨ˆåŸå‰‡ï¼š
1. ä½¿ç”¨æ˜ç¢ºçš„è¦å‰‡é€²è¡Œè‡ªå‹•åŒ–æª¢æ ¸
2. é»‘åå–®è‡ªå‹•æ‹’çµ•ã€å…¨é€šéè‡ªå‹•æ ¸å‡†
3. æœ‰è­¦ç¤ºé …ç›®æ™‚æ¨™ç¤ºç‚ºã€Œéœ€ä¸»ç®¡äººå·¥å¯©æŸ¥ã€
"""

import streamlit as st
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional
from core.db_manager_multiuser import DBManagerMultiUser


class QualificationChecker:
    """è³‡æ ¼æª¢æ ¸æ ¸å¿ƒé‚è¼¯"""

    def __init__(self, user_id=None):
        # ä½¿ç”¨ M5 å°ˆç”¨çš„å–®ä¸€è³‡æ–™åº« - åŒ…å« 4 å€‹è¡¨ (employees, performance, training, separation)
        # æ”¯æ´å¤šç”¨æˆ¶è³‡æ–™éš”é›¢
        self.user_id = user_id
        self.db = DBManagerMultiUser('m5_qualification', user_id=user_id)
        # ç‚ºäº†å‘å¾Œå…¼å®¹å’Œç¨‹å¼ç¢¼å¯è®€æ€§ï¼Œä¿ç•™é€™äº›åˆ¥å
        self.db_employees = self.db
        self.db_performance = self.db
        self.db_training = self.db
        self.db_separation = self.db

    @staticmethod
    def find_column(df: pd.DataFrame, possible_names: List[str]) -> Optional[str]:
        """
        æ™ºæ…§æŸ¥æ‰¾æ¬„ä½åç¨±ï¼ˆä¸å€åˆ†å¤§å°å¯«ã€æ”¯æ´å¤šç¨®è®Šé«”ï¼‰

        Args:
            df: DataFrame
            possible_names: å¯èƒ½çš„æ¬„ä½åç¨±åˆ—è¡¨

        Returns:
            æ‰¾åˆ°çš„æ¬„ä½åç¨±ï¼Œè‹¥æ‰¾ä¸åˆ°å‰‡è¿”å› None
        """
        df_columns_lower = {col.lower().strip(): col for col in df.columns}

        for name in possible_names:
            name_lower = name.lower().strip()
            if name_lower in df_columns_lower:
                return df_columns_lower[name_lower]

        return None

    @staticmethod
    def validate_required_columns(df: pd.DataFrame, column_mapping: Dict[str, List[str]]) -> tuple[bool, List[str]]:
        """
        é©—è­‰å¿…å¡«æ¬„ä½æ˜¯å¦å­˜åœ¨

        Args:
            df: DataFrame
            column_mapping: {é¡¯ç¤ºåç¨±: [å¯èƒ½çš„æ¬„ä½åç¨±åˆ—è¡¨]}

        Returns:
            (æ˜¯å¦å…¨éƒ¨å­˜åœ¨, ç¼ºå°‘çš„æ¬„ä½åˆ—è¡¨)
        """
        missing = []
        for display_name, possible_names in column_mapping.items():
            if QualificationChecker.find_column(df, possible_names) is None:
                missing.append(f"{display_name} ({'/'.join(possible_names[:2])})")

        return len(missing) == 0, missing

    def check(self, name: str, id_number: str = None) -> Dict[str, Any]:
        """
        åŸ·è¡Œè³‡æ ¼æª¢æ ¸

        Args:
            name: å§“å
            id_number: èº«åˆ†è­‰å­—è™Ÿï¼ˆé¸å¡«ï¼Œè‹¥ä¸æä¾›å‰‡åªç”¨å§“åæŸ¥è©¢ï¼‰

        Returns:
            æª¢æ ¸çµæœå­—å…¸
        """
        result = {
            'name': name,
            'id_number': id_number if id_number else 'N/A',
            'checks': [],
            'overall_status': 'PENDING',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        # Step 1: æŸ¥è©¢å“¡å·¥åŸºæœ¬è³‡æ–™
        employee = self._find_employee_by_name(name) if not id_number else self._find_employee(id_number)

        if not employee:
            result['overall_status'] = 'NOT_FOUND'
            result['checks'].append({
                'item': 'å“¡å·¥è³‡æ–™æŸ¥è©¢',
                'status': 'FAIL',
                'detail': 'æŸ¥ç„¡æ­¤å“¡å·¥è¨˜éŒ„ï¼Œå¯èƒ½æœªæ›¾åœ¨æœ¬å…¬å¸ä»»è·'
            })
            return result

        result['emp_id'] = employee['emp_id']
        result['checks'].append({
            'item': 'å“¡å·¥è³‡æ–™æŸ¥è©¢',
            'status': 'PASS',
            'detail': f"å·¥è™Ÿ: {employee['emp_id']}, éƒ¨é–€: {employee.get('department', 'N/A')}"
        })

        # Step 2: é»‘åå–®æ¯”å°
        blacklist_check = self._check_blacklist(employee['emp_id'])
        result['checks'].append(blacklist_check)

        if blacklist_check['status'] == 'FAIL':
            result['overall_status'] = 'REJECTED'
            result['rejection_reason'] = 'åˆ—æ–¼é»‘åå–®ä¸­ï¼Œä¸å¾—å›ä»»'
            return result

        # Step 3: é›¢è·ç´€éŒ„æŸ¥è©¢
        separation_check = self._check_separation(employee['emp_id'])
        result['checks'].append(separation_check)

        # Step 4: æ­·å²ç¸¾æ•ˆæŸ¥è©¢
        performance_check = self._check_performance(employee['emp_id'])
        result['checks'].append(performance_check)

        # Step 5: è¨“ç·´ç´€éŒ„æŸ¥è©¢ï¼ˆé¡å¤–åƒè€ƒï¼‰
        training_check = self._check_training(employee['emp_id'])
        result['checks'].append(training_check)

        # Step 6: ç¶œåˆåˆ¤æ–·
        warnings = [c for c in result['checks'] if c['status'] == 'WARNING']

        if not warnings:
            # å…¨éƒ¨ PASSï¼Œè‡ªå‹•æ ¸å‡†
            result['overall_status'] = 'APPROVED'
            result['recommendation'] = 'âœ… æ‰€æœ‰æª¢æ ¸é …ç›®é€šéï¼Œå»ºè­°æ ¸å‡†å›ä»»'
        else:
            # æœ‰è­¦ç¤ºé …ç›®ï¼Œéœ€è¦äººå·¥å¯©æŸ¥
            result['overall_status'] = 'REVIEW_REQUIRED'
            result['recommendation'] = f"âš ï¸ æœ‰ {len(warnings)} å€‹è­¦ç¤ºé …ç›®ï¼Œéœ€è¦ä¸»ç®¡äººå·¥å¯©æŸ¥"
            result['warnings'] = warnings
            result['review_notes'] = self._generate_review_notes(warnings)

        return result

    def _generate_review_notes(self, warnings: List[Dict]) -> str:
        """ç”Ÿæˆå¯©æŸ¥å»ºè­°"""
        notes = ["å»ºè­°ä¸»ç®¡é‡é»è©•ä¼°ä»¥ä¸‹é …ç›®ï¼š\n"]

        for i, warning in enumerate(warnings, 1):
            notes.append(f"{i}. {warning['item']}: {warning['detail']}")

        return "\n".join(notes)

    def _find_employee(self, id_number: str) -> Optional[Dict]:
        """æ ¹æ“šèº«åˆ†è­‰å­—è™ŸæŸ¥è©¢å“¡å·¥"""
        import hashlib

        # Hash the id_number for comparison
        id_number_hash = hashlib.sha256(id_number.encode()).hexdigest()

        conn = self.db_employees._get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM employees WHERE id_number_hash = ?", (id_number_hash,))
        row = cursor.fetchone()
        conn.close()

        if row:
            return dict(row)
        return None

    def _find_employee_by_name(self, name: str) -> Optional[Dict]:
        """æ ¹æ“šå§“åæŸ¥è©¢å“¡å·¥"""
        conn = self.db_employees._get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM employees WHERE name = ?", (name,))
        row = cursor.fetchone()
        conn.close()

        if row:
            return dict(row)
        return None

    def _check_blacklist(self, emp_id: str) -> Dict[str, Any]:
        """é»‘åå–®æª¢æŸ¥"""
        sep_record = self.db_separation.get_separation_record(emp_id)

        if sep_record and sep_record.get('blacklist'):
            return {
                'item': 'é»‘åå–®æ¯”å°',
                'status': 'FAIL',
                'detail': f"åˆ—æ–¼é»‘åå–®ä¸­ï¼ˆé›¢è·æ—¥æœŸ: {sep_record.get('separation_date', 'N/A')}ï¼‰",
                'data': sep_record
            }
        else:
            return {
                'item': 'é»‘åå–®æ¯”å°',
                'status': 'PASS',
                'detail': 'æœªåœ¨é»‘åå–®'
            }

    def _check_separation(self, emp_id: str) -> Dict[str, Any]:
        """é›¢è·ç´€éŒ„æª¢æŸ¥"""
        sep_record = self.db_separation.get_separation_record(emp_id)

        if not sep_record:
            return {
                'item': 'é›¢è·ç´€éŒ„',
                'status': 'INFO',
                'detail': 'ç„¡é›¢è·ç´€éŒ„ï¼ˆåœ¨è·æˆ–å¾æœªé›¢è·ï¼‰'
            }

        # åˆ†æé›¢è·é¡å‹
        sep_type = sep_record.get('separation_type', '')
        reason = sep_record.get('reason', 'æœªå¡«å¯«')
        sep_date = sep_record.get('separation_date', 'N/A')

        if sep_type in ['è³‡é£', 'é–‹é™¤']:
            return {
                'item': 'é›¢è·ç´€éŒ„',
                'status': 'WARNING',
                'detail': f"éè‡ªé¡˜é›¢è·ï¼ˆ{sep_type}ï¼‰æ–¼ {sep_date}ï¼ŒåŸå› : {reason}",
                'data': sep_record
            }
        else:
            return {
                'item': 'é›¢è·ç´€éŒ„',
                'status': 'PASS',
                'detail': f"è‡ªé¡˜é›¢è·æ–¼ {sep_date}ï¼ŒåŸå› : {reason}",
                'data': sep_record
            }

    def _check_performance(self, emp_id: str) -> Dict[str, Any]:
        """æ­·å²ç¸¾æ•ˆæª¢æŸ¥"""
        perf_records = self.db_performance.get_performance_history(emp_id)

        if not perf_records:
            return {
                'item': 'æ­·å²ç¸¾æ•ˆç´€éŒ„',
                'status': 'INFO',
                'detail': 'ç„¡ç¸¾æ•ˆç´€éŒ„'
            }

        # åˆ†æç¸¾æ•ˆ
        df = pd.DataFrame(perf_records)
        low_perf = df[df['rating'].isin(['C', 'D', 'E'])]

        if len(low_perf) > 0:
            avg_score = df['score'].mean() if 'score' in df.columns else 0
            return {
                'item': 'æ­·å²ç¸¾æ•ˆç´€éŒ„',
                'status': 'WARNING',
                'detail': f"æ›¾æœ‰ {len(low_perf)} æ¬¡ä½ç¸¾æ•ˆç´€éŒ„ï¼ˆC/D/Eï¼‰ï¼Œå¹³å‡åˆ†æ•¸: {avg_score:.1f}",
                'data': perf_records
            }
        else:
            avg_score = df['score'].mean() if 'score' in df.columns else 0
            return {
                'item': 'æ­·å²ç¸¾æ•ˆç´€éŒ„',
                'status': 'PASS',
                'detail': f"ç¸¾æ•ˆè‰¯å¥½ï¼Œå¹³å‡åˆ†æ•¸: {avg_score:.1f}ï¼Œå…± {len(perf_records)} ç­†è¨˜éŒ„",
                'data': perf_records
            }

    def _check_training(self, emp_id: str) -> Dict[str, Any]:
        """è¨“ç·´ç´€éŒ„æª¢æŸ¥"""
        training_records = self.db_training.get_training_history(emp_id)

        if not training_records:
            return {
                'item': 'è¨“ç·´ç´€éŒ„',
                'status': 'INFO',
                'detail': 'ç„¡è¨“ç·´ç´€éŒ„'
            }

        df = pd.DataFrame(training_records)
        total_hours = df['hours'].sum() if 'hours' in df.columns else 0

        return {
            'item': 'è¨“ç·´ç´€éŒ„',
            'status': 'INFO',
            'detail': f"ç¸½å®Œè¨“æ™‚æ•¸: {total_hours} å°æ™‚ï¼Œå…± {len(training_records)} å€‹èª²ç¨‹",
            'data': training_records
        }


def render():
    """æ¸²æŸ“è³‡æ ¼æª¢æ ¸å™¨ä»‹é¢"""
    st.header("âœ… è³‡æ ¼æª¢æ ¸å™¨")
    st.caption("é›¢è·å›ä»»è³‡æ ¼æª¢æ ¸ç³»çµ± - è¦å‰‡å¼è‡ªå‹•åŒ–æª¢æ ¸")

    # å–å¾—ç•¶å‰ç™»å…¥ç”¨æˆ¶çš„ user_id
    user_id = st.session_state.user_info['user_id']

    # åˆå§‹åŒ– checkerï¼ˆæ”¯æ´å¤šç”¨æˆ¶ï¼‰
    if 'checker' not in st.session_state:
        st.session_state.checker = QualificationChecker(user_id=user_id)

    # åˆå§‹åŒ–æª¢æ ¸çµæœå„²å­˜ï¼ˆç¢ºä¿ä¸€å®šæœƒåˆå§‹åŒ–ï¼Œé¿å… AttributeErrorï¼‰
    if 'check_results' not in st.session_state:
        st.session_state.check_results = {}

    if 'show_batch_export' not in st.session_state:
        st.session_state.show_batch_export = False

    # Tab åˆ†é 
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ è³‡æ ¼æª¢æ ¸", "ğŸ“¥ è³‡æ–™åŒ¯å…¥", "ğŸ—„ï¸ è³‡æ–™åº«ç®¡ç†"])

    # Tab 1: è³‡æ ¼æª¢æ ¸
    with tab1:
        st.subheader("å“¡å·¥è³‡æ ¼æª¢æ ¸")

        # å–å¾—æ‰€æœ‰å·²åŒ¯å…¥çš„å“¡å·¥æ¸…å–®
        db_employees = st.session_state.checker.db_employees
        conn = db_employees._get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT emp_id, name, id_number_hash, department FROM employees ORDER BY emp_id")
        all_employees = [dict(row) for row in cursor.fetchall()]
        conn.close()

        if not all_employees:
            st.warning("âš ï¸ è³‡æ–™åº«ä¸­å°šç„¡å“¡å·¥è³‡æ–™ï¼Œè«‹å…ˆåˆ°ã€Œè³‡æ–™åŒ¯å…¥ã€é é¢åŒ¯å…¥æ¸¬è©¦è³‡æ–™")
        else:
            st.info(f"ğŸ“Š è³‡æ–™åº«ä¸­å…±æœ‰ {len(all_employees)} ä½å“¡å·¥è¨˜éŒ„")

            # é¸æ“‡æª¢æ ¸æ¨¡å¼
            check_mode = st.radio(
                "æª¢æ ¸æ¨¡å¼",
                options=["å–®ä¸€æª¢æ ¸", "æ‰¹æ¬¡æª¢æ ¸"],
                horizontal=True
            )

            if check_mode == "å–®ä¸€æª¢æ ¸":
                # å–®ä¸€å“¡å·¥æª¢æ ¸
                employee_options = {f"{emp['emp_id']} - {emp['name']} ({emp.get('department', 'N/A')})": emp for emp in all_employees}

                selected_option = st.selectbox(
                    "é¸æ“‡è¦æª¢æ ¸çš„å“¡å·¥",
                    options=[""] + list(employee_options.keys()),
                    format_func=lambda x: "è«‹é¸æ“‡å“¡å·¥..." if x == "" else x
                )

                if selected_option and selected_option != "":
                    selected_emp = employee_options[selected_option]

                    st.write("---")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**å·¥è™Ÿ**: {selected_emp['emp_id']}")
                        st.write(f"**å§“å**: {selected_emp['name']}")
                    with col2:
                        st.write(f"**éƒ¨é–€**: {selected_emp.get('department', 'N/A')}")

                    if st.button("ğŸ” åŸ·è¡Œæª¢æ ¸", type="primary"):
                        with st.spinner("æª¢æ ¸ä¸­..."):
                            # ä½¿ç”¨å§“åç›´æ¥æª¢æ ¸ï¼ˆä¸éœ€è¦èº«åˆ†è­‰å­—è™Ÿï¼‰
                            result = st.session_state.checker.check(selected_emp['name'], None)
                            st.session_state.last_check_result = result
                            # åŒæ™‚å„²å­˜åˆ°æ‰¹æ¬¡çµæœä¸­
                            st.session_state.check_results[selected_emp['emp_id']] = result

            else:
                # æ‰¹æ¬¡æª¢æ ¸
                employee_options = [f"{emp['emp_id']} - {emp['name']} ({emp.get('department', 'N/A')})" for emp in all_employees]

                selected_options = st.multiselect(
                    "é¸æ“‡è¦æª¢æ ¸çš„å“¡å·¥ï¼ˆå¯å¤šé¸ï¼‰",
                    options=employee_options,
                    help="å¯ä»¥ä½¿ç”¨ Ctrl/Cmd å¤šé¸ï¼Œæˆ–åœ¨ä¸‹æ‹‰é¸å–®ä¸­é€ä¸€å‹¾é¸"
                )

                if selected_options:
                    st.info(f"âœ… å·²é¸æ“‡ {len(selected_options)} ä½å“¡å·¥")

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if st.button("ğŸ” æ‰¹æ¬¡åŸ·è¡Œæª¢æ ¸", type="primary"):
                            progress_bar = st.progress(0)
                            status_text = st.empty()

                            for idx, option in enumerate(selected_options):
                                emp_id = option.split(" - ")[0]
                                emp_name = option.split(" - ")[1].split(" (")[0]

                                status_text.text(f"æª¢æ ¸ä¸­... {emp_name} ({idx + 1}/{len(selected_options)})")

                                # åŸ·è¡Œæª¢æ ¸ï¼ˆä¸éœ€è¦èº«åˆ†è­‰å­—è™Ÿï¼‰
                                result = st.session_state.checker.check(emp_name, None)
                                st.session_state.check_results[emp_id] = result

                                progress_bar.progress((idx + 1) / len(selected_options))

                            status_text.text("âœ… æ‰¹æ¬¡æª¢æ ¸å®Œæˆï¼")
                            st.success(f"å·²å®Œæˆ {len(selected_options)} ä½å“¡å·¥çš„è³‡æ ¼æª¢æ ¸")
                            st.rerun()

                    with col2:
                        if st.session_state.check_results:
                            if st.button("ğŸ—‘ï¸ æ¸…é™¤æª¢æ ¸çµæœ"):
                                st.session_state.check_results = {}
                                st.rerun()

                    with col3:
                        if st.session_state.check_results:
                            if st.button("ğŸ“¥ æ‰¹æ¬¡åŒ¯å‡ºå ±å‘Š"):
                                st.session_state.show_batch_export = True

        # é¡¯ç¤ºæ‰¹æ¬¡æª¢æ ¸çµæœæ‘˜è¦
        if st.session_state.check_results:
            st.divider()
            st.subheader("ğŸ“Š æ‰¹æ¬¡æª¢æ ¸çµæœæ‘˜è¦")

            # çµ±è¨ˆå„ç‹€æ…‹æ•¸é‡
            status_counts = {'APPROVED': 0, 'REVIEW_REQUIRED': 0, 'REJECTED': 0, 'NOT_FOUND': 0}
            for result in st.session_state.check_results.values():
                status = result.get('overall_status', 'NOT_FOUND')
                status_counts[status] = status_counts.get(status, 0) + 1

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âœ… å»ºè­°æ ¸å‡†", status_counts['APPROVED'])
            with col2:
                st.metric("âš ï¸ éœ€è¦å¯©æŸ¥", status_counts['REVIEW_REQUIRED'])
            with col3:
                st.metric("âŒ ä¸å»ºè­°æ ¸å‡†", status_counts['REJECTED'])
            with col4:
                st.metric("ğŸ“Š ç¸½è¨ˆ", len(st.session_state.check_results))

            # é¡¯ç¤ºæª¢æ ¸çµæœè¡¨æ ¼
            with st.expander("ğŸ“‹ æŸ¥çœ‹è©³ç´°çµæœ", expanded=True):
                results_list = []
                for emp_id, result in st.session_state.check_results.items():
                    status_text_map = {
                        'APPROVED': 'âœ… å»ºè­°æ ¸å‡†',
                        'REJECTED': 'âŒ ä¸å»ºè­°æ ¸å‡†',
                        'REVIEW_REQUIRED': 'âš ï¸ éœ€è¦å¯©æŸ¥',
                        'NOT_FOUND': 'âŒ æŸ¥ç„¡è³‡æ–™'
                    }
                    results_list.append({
                        'å·¥è™Ÿ': emp_id,
                        'å§“å': result.get('name', 'N/A'),
                        'æª¢æ ¸ç‹€æ…‹': status_text_map.get(result.get('overall_status'), 'æœªçŸ¥'),
                        'ç³»çµ±å»ºè­°': result.get('recommendation', 'N/A'),
                        'æª¢æ ¸æ™‚é–“': result.get('timestamp', 'N/A')
                    })

                results_df = pd.DataFrame(results_list)
                st.dataframe(results_df, use_container_width=True)

        # æ‰¹æ¬¡åŒ¯å‡ºåŠŸèƒ½
        if 'show_batch_export' in st.session_state and st.session_state.show_batch_export:
            st.divider()
            st.subheader("ğŸ“¥ æ‰¹æ¬¡åŒ¯å‡ºæª¢æ ¸å ±å‘Š")

            from io import BytesIO

            # å»ºç«‹æ‰¹æ¬¡å ±å‘Š
            all_summaries = []
            all_details = []

            status_text_map = {
                'APPROVED': 'âœ… å»ºè­°æ ¸å‡†',
                'REJECTED': 'âŒ ä¸å»ºè­°æ ¸å‡†',
                'REVIEW_REQUIRED': 'âš ï¸ éœ€è¦å¯©æŸ¥',
                'NOT_FOUND': 'âŒ æŸ¥ç„¡è³‡æ–™'
            }

            for emp_id, result in st.session_state.check_results.items():
                # æ‘˜è¦è³‡æ–™
                all_summaries.append({
                    'å·¥è™Ÿ': emp_id,
                    'å§“å': result.get('name', 'N/A'),
                    'æª¢æ ¸æ™‚é–“': result.get('timestamp', 'N/A'),
                    'æª¢æ ¸ç‹€æ…‹': status_text_map.get(result.get('overall_status'), 'æœªçŸ¥'),
                    'ç³»çµ±å»ºè­°': result.get('recommendation', 'N/A'),
                    'å¯©æŸ¥è¦é»': result.get('review_notes', 'N/A')
                })

                # æ˜ç´°è³‡æ–™
                for check in result.get('checks', []):
                    all_details.append({
                        'å·¥è™Ÿ': emp_id,
                        'å§“å': result.get('name', 'N/A'),
                        'æª¢æ ¸é …ç›®': check.get('item', 'N/A'),
                        'ç‹€æ…‹': check.get('status', 'N/A'),
                        'è©³ç´°èªªæ˜': check.get('detail', 'N/A')
                    })

            summary_df = pd.DataFrame(all_summaries)
            details_df = pd.DataFrame(all_details)

            # ç”Ÿæˆ Excel æª”æ¡ˆ
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                summary_df.to_excel(writer, index=False, sheet_name='æª¢æ ¸æ‘˜è¦')
                details_df.to_excel(writer, index=False, sheet_name='æª¢æ ¸æ˜ç´°')

            output.seek(0)

            st.download_button(
                label=f'ğŸ’¾ ä¸‹è¼‰æ‰¹æ¬¡æª¢æ ¸å ±å‘Š ({len(st.session_state.check_results)} ä½å“¡å·¥)',
                data=output,
                file_name=f"batch_qualification_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )

            if st.button("é—œé–‰åŒ¯å‡º"):
                st.session_state.show_batch_export = False
                st.rerun()

        # é¡¯ç¤ºå–®ä¸€æª¢æ ¸çµæœï¼ˆåœ¨å–®ä¸€æª¢æ ¸æ¨¡å¼ä¸‹ï¼‰
        if 'last_check_result' in st.session_state and check_mode == "å–®ä¸€æª¢æ ¸":
            result = st.session_state.last_check_result

            st.divider()
            st.subheader("ğŸ“„ æª¢æ ¸å ±å‘Š")

            # é¡¯ç¤ºæ•´é«”ç‹€æ…‹
            status_color = {
                'APPROVED': 'success',
                'REJECTED': 'error',
                'REVIEW_REQUIRED': 'warning',
                'NOT_FOUND': 'error',
                'PENDING': 'info'
            }

            status_text = {
                'APPROVED': 'âœ… å»ºè­°æ ¸å‡†',
                'REJECTED': 'âŒ ä¸å»ºè­°æ ¸å‡†',
                'REVIEW_REQUIRED': 'âš ï¸ éœ€è¦å¯©æŸ¥',
                'NOT_FOUND': 'âŒ æŸ¥ç„¡è³‡æ–™',
                'PENDING': 'â³ æª¢æ ¸ä¸­'
            }

            status = result['overall_status']
            getattr(st, status_color[status])(f"**æª¢æ ¸ç‹€æ…‹**: {status_text[status]}")

            # é¡¯ç¤ºæª¢æ ¸é …ç›®
            st.write("**æª¢æ ¸é …ç›®æ˜ç´°**:")
            for i, check in enumerate(result['checks']):
                icon = {
                    'PASS': 'âœ…',
                    'WARNING': 'âš ï¸',
                    'FAIL': 'âŒ',
                    'INFO': 'â„¹ï¸'
                }
                st.write(f"{icon.get(check['status'], 'â€¢')} **{check['item']}**: {check['detail']}")

            # é¡¯ç¤ºå»ºè­°
            if 'recommendation' in result:
                st.info(f"**ç³»çµ±å»ºè­°**: {result['recommendation']}")

            # é¡¯ç¤ºå¯©æŸ¥è¦é»ï¼ˆåƒ…åœ¨ REVIEW_REQUIRED æ™‚é¡¯ç¤ºï¼‰
            if status == 'REVIEW_REQUIRED' and 'review_notes' in result:
                st.divider()
                st.warning("**âš ï¸ éœ€è¦ä¸»ç®¡äººå·¥å¯©æŸ¥**")
                st.write(result['review_notes'])

            # åŒ¯å‡ºå–®ä¸€å ±å‘ŠæŒ‰éˆ•
            st.divider()
            if st.button("ğŸ“¥ åŒ¯å‡ºæ­¤æª¢æ ¸å ±å‘Š"):
                # å»ºç«‹å ±å‘Š DataFrame
                report_data = {
                    'æª¢æ ¸æ™‚é–“': [result['timestamp']],
                    'å§“å': [result['name']],
                    'å·¥è™Ÿ': [result.get('emp_id', 'N/A')],
                    'æª¢æ ¸ç‹€æ…‹': [status_text[status]],
                    'ç³»çµ±å»ºè­°': [result.get('recommendation', 'N/A')],
                    'å¯©æŸ¥è¦é»': [result.get('review_notes', 'N/A')]
                }

                report_df = pd.DataFrame(report_data)

                # æª¢æ ¸æ˜ç´°
                checks_df = pd.DataFrame([
                    {
                        'æª¢æ ¸é …ç›®': check['item'],
                        'ç‹€æ…‹': check['status'],
                        'è©³ç´°èªªæ˜': check['detail']
                    }
                    for check in result['checks']
                ])

                # ä½¿ç”¨ ExcelWriter å»ºç«‹å¤šåˆ†é å ±å‘Š
                from io import BytesIO
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    report_df.to_excel(writer, index=False, sheet_name='æª¢æ ¸æ‘˜è¦')
                    checks_df.to_excel(writer, index=False, sheet_name='æª¢æ ¸æ˜ç´°')

                output.seek(0)

                st.download_button(
                    label='ğŸ’¾ ä¸‹è¼‰æª¢æ ¸å ±å‘Š',
                    data=output,
                    file_name=f"qualification_check_{result.get('emp_id', 'unknown')}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )

    # Tab 2: è³‡æ–™åŒ¯å…¥
    with tab2:
        st.subheader("ğŸ“¥ è³‡æ–™åŒ¯å…¥")
        st.caption("åŒ¯å…¥æ¸¬è©¦è³‡æ–™ä»¥é€²è¡Œè³‡æ ¼æª¢æ ¸")

        import_tab1, import_tab2, import_tab3, import_tab4 = st.tabs([
            "å“¡å·¥è³‡æ–™", "é›¢è·è¨˜éŒ„", "ç¸¾æ•ˆè³‡æ–™", "è¨“ç·´è¨˜éŒ„"
        ])

        # å“¡å·¥è³‡æ–™åŒ¯å…¥
        with import_tab1:
            st.write("**ä¸Šå‚³å“¡å·¥ä¸»æª”**")

            with st.expander("ğŸ“‹ å¿…å¡«æ¬„ä½èªªæ˜", expanded=False):
                st.markdown("""
                **å¿…å¡«æ¬„ä½**ï¼ˆç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥ä»¥ä¸‹ä»»ä¸€åç¨±ï¼‰ï¼š
                - **å·¥è™Ÿ**ï¼š`emp_id` / `å·¥è™Ÿ` / `å“¡å·¥ç·¨è™Ÿ` / `employee_id`
                - **å§“å**ï¼š`name` / `å§“å` / `å“¡å·¥å§“å` / `employee_name`

                **é¸å¡«æ¬„ä½**ï¼š
                - **èº«åˆ†è­‰**ï¼š`id_number` / `èº«åˆ†è­‰å­—è™Ÿ` / `èº«ä»½è­‰` / `id`
                - **éƒ¨é–€**ï¼š`department` / `éƒ¨é–€` / `dept`
                - **åˆ°è·æ—¥**ï¼š`hire_date` / `åˆ°è·æ—¥` / `å…¥è·æ—¥æœŸ` / `arrival_date`
                - **ç‹€æ…‹**ï¼š`status` / `ç‹€æ…‹`ï¼ˆé è¨­ç‚ºã€Œé›¢è·ã€ï¼‰

                âœ… ç³»çµ±æ”¯æ´**ä¸å€åˆ†å¤§å°å¯«**ï¼Œ`EMP_ID` å’Œ `emp_id` éƒ½å¯ä»¥è­˜åˆ¥
                """)

            emp_file = st.file_uploader("é¸æ“‡å“¡å·¥è³‡æ–™æª”æ¡ˆ", type=['xlsx', 'csv'], key='emp_file')

            if emp_file:
                try:
                    emp_df = pd.read_excel(emp_file) if emp_file.name.endswith('xlsx') else pd.read_csv(emp_file)

                    st.write(f"**æª”æ¡ˆé è¦½** ({len(emp_df)} ç­†è³‡æ–™):")
                    st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
                    st.dataframe(emp_df)

                    # é©—è­‰å¿…å¡«æ¬„ä½
                    required_cols = {
                        'å·¥è™Ÿ': ['emp_id', 'å·¥è™Ÿ', 'å“¡å·¥ç·¨è™Ÿ', 'employee_id', 'id'],
                        'å§“å': ['name', 'å§“å', 'å“¡å·¥å§“å', 'employee_name']
                    }

                    is_valid, missing = st.session_state.checker.validate_required_columns(emp_df, required_cols)

                    if not is_valid:
                        st.error(f"âŒ ç¼ºå°‘å¿…å¡«æ¬„ä½ï¼š{', '.join(missing)}")
                        st.info("è«‹ç¢ºèªæª”æ¡ˆåŒ…å«å¿…å¡«æ¬„ä½ï¼Œæˆ–åƒè€ƒä¸Šæ–¹ã€Œå¿…å¡«æ¬„ä½èªªæ˜ã€")
                    else:
                        st.success("âœ… æ¬„ä½é©—è­‰é€šé")

                        # é¡¯ç¤ºè­˜åˆ¥åˆ°çš„æ¬„ä½
                        col_map = {}
                        all_possible_cols = {
                            'å·¥è™Ÿ': ['emp_id', 'å·¥è™Ÿ', 'å“¡å·¥ç·¨è™Ÿ', 'employee_id', 'id'],
                            'å§“å': ['name', 'å§“å', 'å“¡å·¥å§“å', 'employee_name'],
                            'èº«åˆ†è­‰': ['id_number', 'èº«åˆ†è­‰å­—è™Ÿ', 'èº«ä»½è­‰', 'id_card'],
                            'éƒ¨é–€': ['department', 'éƒ¨é–€', 'dept'],
                            'åˆ°è·æ—¥': ['hire_date', 'åˆ°è·æ—¥', 'å…¥è·æ—¥æœŸ', 'arrival_date'],
                            'ç‹€æ…‹': ['status', 'ç‹€æ…‹']
                        }

                        for field, possible_names in all_possible_cols.items():
                            found = st.session_state.checker.find_column(emp_df, possible_names)
                            if found:
                                col_map[field] = found

                        with st.expander("ğŸ” å·²è­˜åˆ¥çš„æ¬„ä½å°æ‡‰", expanded=False):
                            for field, col_name in col_map.items():
                                st.text(f"  {field} â†’ {col_name}")

                        if st.button("åŒ¯å…¥å“¡å·¥è³‡æ–™", key='import_emp', type='primary'):
                            success_count = 0
                            error_count = 0
                            errors = []

                            for idx, row in emp_df.iterrows():
                                try:
                                    result = st.session_state.checker.db_employees.add_employee(
                                        emp_id=row[col_map['å·¥è™Ÿ']] if 'å·¥è™Ÿ' in col_map else None,
                                        name=row[col_map['å§“å']] if 'å§“å' in col_map else None,
                                        id_number=row[col_map['èº«åˆ†è­‰']] if 'èº«åˆ†è­‰' in col_map else None,
                                        department=row[col_map['éƒ¨é–€']] if 'éƒ¨é–€' in col_map else None,
                                        hire_date=row[col_map['åˆ°è·æ—¥']] if 'åˆ°è·æ—¥' in col_map else None,
                                        status=row[col_map['ç‹€æ…‹']] if 'ç‹€æ…‹' in col_map else 'é›¢è·'
                                    )
                                    if result:
                                        success_count += 1
                                    else:
                                        error_count += 1
                                except Exception as e:
                                    error_count += 1
                                    errors.append(f"ç¬¬ {idx+2} åˆ—: {str(e)}")

                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸåŒ¯å…¥ {success_count}/{len(emp_df)} ç­†å“¡å·¥è³‡æ–™")
                            if error_count > 0:
                                st.warning(f"âš ï¸ {error_count} ç­†è³‡æ–™åŒ¯å…¥å¤±æ•—")
                                if errors:
                                    with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                                        for err in errors[:10]:  # åªé¡¯ç¤ºå‰10å€‹éŒ¯èª¤
                                            st.text(err)

                            if success_count > 0:
                                st.rerun()
                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {str(e)}")

        # é›¢è·è¨˜éŒ„åŒ¯å…¥
        with import_tab2:
            st.write("**ä¸Šå‚³é›¢è·è¨˜éŒ„**")

            with st.expander("ğŸ“‹ å¿…å¡«æ¬„ä½èªªæ˜", expanded=False):
                st.markdown("""
                **å¿…å¡«æ¬„ä½**ï¼ˆç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥ä»¥ä¸‹ä»»ä¸€åç¨±ï¼‰ï¼š
                - **å·¥è™Ÿ**ï¼š`emp_id` / `å·¥è™Ÿ` / `å“¡å·¥ç·¨è™Ÿ` / `employee_id`
                - **é›¢è·æ—¥æœŸ**ï¼š`separation_date` / `é›¢è·æ—¥æœŸ` / `é›¢è·æ™‚é–“`
                - **é›¢è·é¡å‹**ï¼š`separation_type` / `é›¢è·é¡å‹` / `é›¢è·æ€§è³ª`
                - **é›¢è·åŸå› **ï¼š`reason` / `é›¢è·åŸå› ` / `åŸå› `

                **é¸å¡«æ¬„ä½**ï¼š
                - **é»‘åå–®**ï¼š`blacklist` / `é»‘åå–®` (TRUE/FALSE æˆ– 1/0)

                âœ… ç³»çµ±æ”¯æ´**ä¸å€åˆ†å¤§å°å¯«**ï¼Œ`EMP_ID` å’Œ `emp_id` éƒ½å¯ä»¥è­˜åˆ¥
                """)

            sep_file = st.file_uploader("é¸æ“‡é›¢è·è¨˜éŒ„æª”æ¡ˆ", type=['xlsx', 'csv'], key='sep_file')

            if sep_file:
                try:
                    sep_df = pd.read_excel(sep_file) if sep_file.name.endswith('xlsx') else pd.read_csv(sep_file)

                    # å¿…å¡«æ¬„ä½é©—è­‰
                    required_cols = {
                        'å·¥è™Ÿ': ['emp_id', 'å·¥è™Ÿ', 'å“¡å·¥ç·¨è™Ÿ', 'employee_id'],
                        'é›¢è·æ—¥æœŸ': ['separation_date', 'é›¢è·æ—¥æœŸ', 'é›¢è·æ™‚é–“'],
                        'é›¢è·é¡å‹': ['separation_type', 'é›¢è·é¡å‹', 'é›¢è·æ€§è³ª'],
                        'é›¢è·åŸå› ': ['reason', 'é›¢è·åŸå› ', 'åŸå› ']
                    }

                    is_valid, missing = st.session_state.checker.validate_required_columns(sep_df, required_cols)

                    if not is_valid:
                        st.error(f"âŒ ç¼ºå°‘å¿…å¡«æ¬„ä½ï¼š{', '.join(missing)}")
                        st.info("ğŸ’¡ è«‹åƒè€ƒä¸Šæ–¹ã€Œå¿…å¡«æ¬„ä½èªªæ˜ã€ï¼Œç¢ºèªæª”æ¡ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½")
                    else:
                        # é¡¯ç¤ºæ¬„ä½å°æ‡‰
                        st.success("âœ… æ‰€æœ‰å¿…å¡«æ¬„ä½éƒ½å·²æ‰¾åˆ°")

                        col_mapping = {}
                        for display_name, possible_names in required_cols.items():
                            found_col = st.session_state.checker.find_column(sep_df, possible_names)
                            if found_col:
                                col_mapping[display_name] = found_col

                        with st.expander("ğŸ“Š æ¬„ä½å°æ‡‰é—œä¿‚", expanded=False):
                            for display_name, file_col in col_mapping.items():
                                st.write(f"- {display_name} â† `{file_col}`")

                        st.write("**æª”æ¡ˆé è¦½**:")
                        st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
                        st.dataframe(sep_df)

                        if st.button("åŒ¯å…¥é›¢è·è¨˜éŒ„", key='import_sep'):
                            success_count = 0
                            error_count = 0
                            errors = []

                            for idx, row in sep_df.iterrows():
                                try:
                                    emp_id_col = st.session_state.checker.find_column(sep_df, required_cols['å·¥è™Ÿ'])
                                    date_col = st.session_state.checker.find_column(sep_df, required_cols['é›¢è·æ—¥æœŸ'])
                                    type_col = st.session_state.checker.find_column(sep_df, required_cols['é›¢è·é¡å‹'])
                                    reason_col = st.session_state.checker.find_column(sep_df, required_cols['é›¢è·åŸå› '])
                                    blacklist_col = st.session_state.checker.find_column(sep_df, ['blacklist', 'é»‘åå–®'])

                                    result = st.session_state.checker.db_separation.add_separation_record(
                                        emp_id=row[emp_id_col],
                                        separation_date=row[date_col],
                                        separation_type=row[type_col],
                                        reason=row[reason_col],
                                        blacklist=bool(row.get(blacklist_col, False)) if blacklist_col else False
                                    )
                                    if result:
                                        success_count += 1
                                    else:
                                        error_count += 1
                                except Exception as e:
                                    error_count += 1
                                    errors.append(f"ç¬¬ {idx + 2} åˆ—: {str(e)}")

                            # é¡¯ç¤ºåŒ¯å…¥çµæœ
                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸåŒ¯å…¥ {success_count} ç­†é›¢è·è¨˜éŒ„")
                            if error_count > 0:
                                st.warning(f"âš ï¸ {error_count} ç­†è¨˜éŒ„åŒ¯å…¥å¤±æ•—")
                                if errors:
                                    with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                                        for err in errors[:10]:  # æœ€å¤šé¡¯ç¤º 10 å€‹éŒ¯èª¤
                                            st.text(err)

                            st.info(f"ğŸ“Š åŒ¯å…¥çµ±è¨ˆï¼šç¸½è¨ˆ {len(sep_df)} ç­†ï¼ŒæˆåŠŸ {success_count} ç­†ï¼Œå¤±æ•— {error_count} ç­†")
                            st.rerun()

                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {str(e)}")

        # ç¸¾æ•ˆè³‡æ–™åŒ¯å…¥
        with import_tab3:
            st.write("**ä¸Šå‚³ç¸¾æ•ˆè³‡æ–™**")

            with st.expander("ğŸ“‹ å¿…å¡«æ¬„ä½èªªæ˜", expanded=False):
                st.markdown("""
                **å¿…å¡«æ¬„ä½**ï¼ˆç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥ä»¥ä¸‹ä»»ä¸€åç¨±ï¼‰ï¼š
                - **å·¥è™Ÿ**ï¼š`emp_id` / `å·¥è™Ÿ` / `å“¡å·¥ç·¨è™Ÿ` / `employee_id`
                - **å¹´åº¦**ï¼š`year` / `å¹´åº¦` / `è€ƒæ ¸å¹´åº¦`
                - **è€ƒç¸¾ç­‰ç´š**ï¼š`rating` / `è€ƒç¸¾` / `ç­‰ç´š` / `è©•ç­‰`
                - **åˆ†æ•¸**ï¼š`score` / `åˆ†æ•¸` / `ç¸¾æ•ˆåˆ†æ•¸`

                âœ… ç³»çµ±æ”¯æ´**ä¸å€åˆ†å¤§å°å¯«**ï¼Œ`EMP_ID` å’Œ `emp_id` éƒ½å¯ä»¥è­˜åˆ¥
                """)

            perf_file = st.file_uploader("é¸æ“‡ç¸¾æ•ˆè³‡æ–™æª”æ¡ˆ", type=['xlsx', 'csv'], key='perf_file')

            if perf_file:
                try:
                    perf_df = pd.read_excel(perf_file) if perf_file.name.endswith('xlsx') else pd.read_csv(perf_file)

                    # å¿…å¡«æ¬„ä½é©—è­‰
                    required_cols = {
                        'å·¥è™Ÿ': ['emp_id', 'å·¥è™Ÿ', 'å“¡å·¥ç·¨è™Ÿ', 'employee_id'],
                        'å¹´åº¦': ['year', 'å¹´åº¦', 'è€ƒæ ¸å¹´åº¦'],
                        'è€ƒç¸¾ç­‰ç´š': ['rating', 'è€ƒç¸¾', 'ç­‰ç´š', 'è©•ç­‰'],
                        'åˆ†æ•¸': ['score', 'åˆ†æ•¸', 'ç¸¾æ•ˆåˆ†æ•¸']
                    }

                    is_valid, missing = st.session_state.checker.validate_required_columns(perf_df, required_cols)

                    if not is_valid:
                        st.error(f"âŒ ç¼ºå°‘å¿…å¡«æ¬„ä½ï¼š{', '.join(missing)}")
                        st.info("ğŸ’¡ è«‹åƒè€ƒä¸Šæ–¹ã€Œå¿…å¡«æ¬„ä½èªªæ˜ã€ï¼Œç¢ºèªæª”æ¡ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½")
                    else:
                        # é¡¯ç¤ºæ¬„ä½å°æ‡‰
                        st.success("âœ… æ‰€æœ‰å¿…å¡«æ¬„ä½éƒ½å·²æ‰¾åˆ°")

                        col_mapping = {}
                        for display_name, possible_names in required_cols.items():
                            found_col = st.session_state.checker.find_column(perf_df, possible_names)
                            if found_col:
                                col_mapping[display_name] = found_col

                        with st.expander("ğŸ“Š æ¬„ä½å°æ‡‰é—œä¿‚", expanded=False):
                            for display_name, file_col in col_mapping.items():
                                st.write(f"- {display_name} â† `{file_col}`")

                        st.write("**æª”æ¡ˆé è¦½**:")
                        st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
                        st.dataframe(perf_df)

                        if st.button("åŒ¯å…¥ç¸¾æ•ˆè³‡æ–™", key='import_perf'):
                            success_count = 0
                            error_count = 0
                            errors = []

                            for idx, row in perf_df.iterrows():
                                try:
                                    emp_id_col = st.session_state.checker.find_column(perf_df, required_cols['å·¥è™Ÿ'])
                                    year_col = st.session_state.checker.find_column(perf_df, required_cols['å¹´åº¦'])
                                    rating_col = st.session_state.checker.find_column(perf_df, required_cols['è€ƒç¸¾ç­‰ç´š'])
                                    score_col = st.session_state.checker.find_column(perf_df, required_cols['åˆ†æ•¸'])

                                    result = st.session_state.checker.db_performance.add_performance_record(
                                        emp_id=row[emp_id_col],
                                        year=int(row[year_col]),
                                        rating=row[rating_col],
                                        score=float(row[score_col])
                                    )
                                    if result:
                                        success_count += 1
                                    else:
                                        error_count += 1
                                except Exception as e:
                                    error_count += 1
                                    errors.append(f"ç¬¬ {idx + 2} åˆ—: {str(e)}")

                            # é¡¯ç¤ºåŒ¯å…¥çµæœ
                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸåŒ¯å…¥ {success_count} ç­†ç¸¾æ•ˆè³‡æ–™")
                            if error_count > 0:
                                st.warning(f"âš ï¸ {error_count} ç­†è¨˜éŒ„åŒ¯å…¥å¤±æ•—")
                                if errors:
                                    with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                                        for err in errors[:10]:  # æœ€å¤šé¡¯ç¤º 10 å€‹éŒ¯èª¤
                                            st.text(err)

                            st.info(f"ğŸ“Š åŒ¯å…¥çµ±è¨ˆï¼šç¸½è¨ˆ {len(perf_df)} ç­†ï¼ŒæˆåŠŸ {success_count} ç­†ï¼Œå¤±æ•— {error_count} ç­†")
                            st.rerun()

                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {str(e)}")

        # è¨“ç·´è¨˜éŒ„åŒ¯å…¥
        with import_tab4:
            st.write("**ä¸Šå‚³è¨“ç·´è¨˜éŒ„**")

            with st.expander("ğŸ“‹ å¿…å¡«æ¬„ä½èªªæ˜", expanded=False):
                st.markdown("""
                **å¿…å¡«æ¬„ä½**ï¼ˆç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥ä»¥ä¸‹ä»»ä¸€åç¨±ï¼‰ï¼š
                - **å·¥è™Ÿ**ï¼š`emp_id` / `å·¥è™Ÿ` / `å“¡å·¥ç·¨è™Ÿ` / `employee_id`
                - **èª²ç¨‹åç¨±**ï¼š`course_name` / `èª²ç¨‹åç¨±` / `è¨“ç·´èª²ç¨‹`
                - **èª²ç¨‹é¡å‹**ï¼š`course_type` / `èª²ç¨‹é¡å‹` / `è¨“ç·´é¡å‹`
                - **æ™‚æ•¸**ï¼š`hours` / `æ™‚æ•¸` / `è¨“ç·´æ™‚æ•¸`
                - **å®Œè¨“æ—¥æœŸ**ï¼š`completion_date` / `å®Œè¨“æ—¥æœŸ` / `çµè¨“æ—¥æœŸ`

                âœ… ç³»çµ±æ”¯æ´**ä¸å€åˆ†å¤§å°å¯«**ï¼Œ`EMP_ID` å’Œ `emp_id` éƒ½å¯ä»¥è­˜åˆ¥
                """)

            train_file = st.file_uploader("é¸æ“‡è¨“ç·´è¨˜éŒ„æª”æ¡ˆ", type=['xlsx', 'csv'], key='train_file')

            if train_file:
                try:
                    train_df = pd.read_excel(train_file) if train_file.name.endswith('xlsx') else pd.read_csv(train_file)

                    # å¿…å¡«æ¬„ä½é©—è­‰
                    required_cols = {
                        'å·¥è™Ÿ': ['emp_id', 'å·¥è™Ÿ', 'å“¡å·¥ç·¨è™Ÿ', 'employee_id'],
                        'èª²ç¨‹åç¨±': ['course_name', 'èª²ç¨‹åç¨±', 'è¨“ç·´èª²ç¨‹'],
                        'èª²ç¨‹é¡å‹': ['course_type', 'èª²ç¨‹é¡å‹', 'è¨“ç·´é¡å‹'],
                        'æ™‚æ•¸': ['hours', 'æ™‚æ•¸', 'è¨“ç·´æ™‚æ•¸'],
                        'å®Œè¨“æ—¥æœŸ': ['completion_date', 'å®Œè¨“æ—¥æœŸ', 'çµè¨“æ—¥æœŸ']
                    }

                    is_valid, missing = st.session_state.checker.validate_required_columns(train_df, required_cols)

                    if not is_valid:
                        st.error(f"âŒ ç¼ºå°‘å¿…å¡«æ¬„ä½ï¼š{', '.join(missing)}")
                        st.info("ğŸ’¡ è«‹åƒè€ƒä¸Šæ–¹ã€Œå¿…å¡«æ¬„ä½èªªæ˜ã€ï¼Œç¢ºèªæª”æ¡ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½")
                    else:
                        # é¡¯ç¤ºæ¬„ä½å°æ‡‰
                        st.success("âœ… æ‰€æœ‰å¿…å¡«æ¬„ä½éƒ½å·²æ‰¾åˆ°")

                        col_mapping = {}
                        for display_name, possible_names in required_cols.items():
                            found_col = st.session_state.checker.find_column(train_df, possible_names)
                            if found_col:
                                col_mapping[display_name] = found_col

                        with st.expander("ğŸ“Š æ¬„ä½å°æ‡‰é—œä¿‚", expanded=False):
                            for display_name, file_col in col_mapping.items():
                                st.write(f"- {display_name} â† `{file_col}`")

                        st.write("**æª”æ¡ˆé è¦½**:")
                        st.caption('ğŸ’¡ é»æ“Šå³ä¸Šè§’å…¨è¢å¹•æŒ‰éˆ•å¯æŸ¥çœ‹å®Œæ•´è³‡æ–™')
                        st.dataframe(train_df)

                        if st.button("åŒ¯å…¥è¨“ç·´è¨˜éŒ„", key='import_train'):
                            success_count = 0
                            error_count = 0
                            errors = []

                            for idx, row in train_df.iterrows():
                                try:
                                    emp_id_col = st.session_state.checker.find_column(train_df, required_cols['å·¥è™Ÿ'])
                                    course_name_col = st.session_state.checker.find_column(train_df, required_cols['èª²ç¨‹åç¨±'])
                                    course_type_col = st.session_state.checker.find_column(train_df, required_cols['èª²ç¨‹é¡å‹'])
                                    hours_col = st.session_state.checker.find_column(train_df, required_cols['æ™‚æ•¸'])
                                    completion_date_col = st.session_state.checker.find_column(train_df, required_cols['å®Œè¨“æ—¥æœŸ'])

                                    result = st.session_state.checker.db_training.add_training_record(
                                        emp_id=row[emp_id_col],
                                        course_name=row[course_name_col],
                                        course_type=row[course_type_col],
                                        hours=float(row[hours_col]),
                                        completion_date=row[completion_date_col]
                                    )
                                    if result:
                                        success_count += 1
                                    else:
                                        error_count += 1
                                except Exception as e:
                                    error_count += 1
                                    errors.append(f"ç¬¬ {idx + 2} åˆ—: {str(e)}")

                            # é¡¯ç¤ºåŒ¯å…¥çµæœ
                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸåŒ¯å…¥ {success_count} ç­†è¨“ç·´è¨˜éŒ„")
                            if error_count > 0:
                                st.warning(f"âš ï¸ {error_count} ç­†è¨˜éŒ„åŒ¯å…¥å¤±æ•—")
                                if errors:
                                    with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                                        for err in errors[:10]:  # æœ€å¤šé¡¯ç¤º 10 å€‹éŒ¯èª¤
                                            st.text(err)

                            st.info(f"ğŸ“Š åŒ¯å…¥çµ±è¨ˆï¼šç¸½è¨ˆ {len(train_df)} ç­†ï¼ŒæˆåŠŸ {success_count} ç­†ï¼Œå¤±æ•— {error_count} ç­†")
                            st.rerun()

                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {str(e)}")

    # Tab 3: è³‡æ–™åº«ç®¡ç†
    with tab3:
        from io import BytesIO

        st.subheader("ğŸ—„ï¸ è³‡æ–™åº«ç®¡ç†")
        st.warning("âš ï¸ è«‹è¬¹æ…æ“ä½œï¼Œåˆªé™¤å¾Œç„¡æ³•å¾©åŸï¼")

        # é¸æ“‡è¦ç®¡ç†çš„è³‡æ–™åº«
        db_type = st.selectbox("é¸æ“‡è³‡æ–™åº«", [
            "å“¡å·¥è³‡æ–™ (employees)",
            "ç¸¾æ•ˆè³‡æ–™ (performance)",
            "è¨“ç·´è³‡æ–™ (training)",
            "é›¢è·è³‡æ–™ (separation)"
        ])

        # ä½¿ç”¨å–®ä¸€è³‡æ–™åº« m5_qualificationï¼Œæ ¹æ“šé¸æ“‡è¼‰å…¥å°æ‡‰çš„è¡¨
        db = st.session_state.checker.db  # Single database for all tables

        if "å“¡å·¥è³‡æ–™" in db_type:
            table_name = "employees"
            all_data = db.get_all_employees()
        elif "ç¸¾æ•ˆè³‡æ–™" in db_type:
            table_name = "performance"
            all_data = db.get_all_records(table_name='performance')
        elif "è¨“ç·´è³‡æ–™" in db_type:
            table_name = "training"
            all_data = db.get_all_records(table_name='training')
        else:  # é›¢è·è³‡æ–™
            table_name = "separation"
            all_data = db.get_all_records(table_name='separation')

        if all_data:
            st.info(f"ğŸ“Š {db_type} ä¸­å…±æœ‰ {len(all_data)} ç­†è³‡æ–™")

            # é¡¯ç¤ºè³‡æ–™
            df_display = pd.DataFrame(all_data)
            st.dataframe(df_display, use_container_width=True)

            st.divider()

            # ç®¡ç†é¸é …
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("æ¸…ç©ºè³‡æ–™åº«")
                confirm = st.checkbox(f"æˆ‘ç¢ºèªè¦æ¸…ç©º {db_type} çš„æ‰€æœ‰è³‡æ–™", key=f"confirm_clear_{db_type}")
                if confirm:
                    if st.button("ğŸ—‘ï¸ ç¢ºèªæ¸…ç©º", type="primary", key=f"clear_btn_{db_type}"):
                        try:
                            db.clear_all_data(table_name=table_name)
                            st.success(f"{db_type} å·²æ¸…ç©º")
                            st.rerun()
                        except Exception as e:
                            st.error(f"æ¸…ç©ºå¤±æ•—: {str(e)}")

            with col2:
                st.subheader("åŒ¯å‡ºè³‡æ–™")
                # åŒ¯å‡ºè³‡æ–™åº«å…§å®¹
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_display.to_excel(writer, index=False, sheet_name=table_name)
                output.seek(0)

                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰å‚™ä»½æª”æ¡ˆ",
                    data=output,
                    file_name=f"m5_{table_name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            # ä¾æ¢ä»¶åˆªé™¤
            st.divider()
            st.subheader("ä¾æ¢ä»¶åˆªé™¤")

            if "å“¡å·¥è³‡æ–™" in db_type:
                emp_to_delete = st.multiselect(
                    "é¸æ“‡è¦åˆªé™¤çš„å“¡å·¥",
                    options=[f"{emp['emp_id']} - {emp['name']}" for emp in all_data]
                )

                if emp_to_delete and st.button("åˆªé™¤é¸å®šå“¡å·¥", type="primary"):
                    emp_ids = [e.split(" - ")[0] for e in emp_to_delete]
                    try:
                        for emp_id in emp_ids:
                            db.delete_employee(emp_id)
                        st.success(f"å·²åˆªé™¤ {len(emp_ids)} ä½å“¡å·¥")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆªé™¤å¤±æ•—: {str(e)}")
            else:
                # å…¶ä»–è³‡æ–™åº«æä¾›ä¾å·¥è™Ÿåˆªé™¤
                emp_id_to_delete = st.text_input("è¼¸å…¥è¦åˆªé™¤çš„å·¥è™Ÿ")
                if emp_id_to_delete and st.button("åˆªé™¤æ­¤å·¥è™Ÿçš„æ‰€æœ‰è¨˜éŒ„", type="primary"):
                    try:
                        db.delete_by_emp_id(emp_id_to_delete, table_name=table_name)
                        st.success(f"å·²åˆªé™¤å·¥è™Ÿ {emp_id_to_delete} çš„æ‰€æœ‰è¨˜éŒ„")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆªé™¤å¤±æ•—: {str(e)}")

        else:
            st.info(f"{db_type} ä¸­ç„¡è³‡æ–™")
