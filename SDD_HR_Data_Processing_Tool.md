# Software Design Document (SDD)
# HR è³‡æ–™è™•ç†å·¥å…·å¹³å°

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2025-01-02  
**ç›®æ¨™é–‹ç™¼å·¥å…·**: Claude Code  

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 å°ˆæ¡ˆç›®æ¨™
é–‹ç™¼ä¸€å€‹çµ±ä¸€çš„ HR è³‡æ–™è™•ç†å¹³å°ï¼Œè§£æ±º HR äººå“¡æ—¥å¸¸å·¥ä½œä¸­ã€Œå°ä½†é »ç¹ã€è€—æ™‚è€—åŠ›ã€çš„è³‡æ–™è™•ç†ç—›é»ã€‚

### 1.2 æ ¸å¿ƒè¨­è¨ˆåŸå‰‡
1. **ç¯€çœ API æˆæœ¬**: èƒ½ç”¨ç´” Python è¦å‰‡è§£æ±ºçš„ï¼Œçµ•ä¸å‘¼å« AI
2. **ç¯„æœ¬åŒ–è¨­è¨ˆ**: æ‰€æœ‰è¨­å®šå¯å„²å­˜ç‚ºç¯„æœ¬ï¼Œé‡è¤‡ä½¿ç”¨
3. **æ··åˆå¼ AI**: åƒ…åœ¨è¤‡é›œåˆ¤æ–·æ™‚æ‰å‘¼å« Gemini API
4. **æœ¬åœ°å„ªå…ˆ**: ä¼æ¥­æ•æ„Ÿè³‡æ–™ä¸ä¸Šå‚³é›²ç«¯ï¼Œä½¿ç”¨æœ¬åœ° SQLite

### 1.3 ç›®æ¨™ä½¿ç”¨è€…
ASUS HR éƒ¨é–€äººå“¡ï¼Œå…·å‚™åŸºæœ¬ Excel æ“ä½œèƒ½åŠ›ï¼Œç„¡éœ€ç¨‹å¼èƒŒæ™¯ã€‚

---

## 2. ç³»çµ±æ¶æ§‹

### 2.1 æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Streamlit GUI                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ å ±è¡¨åˆä½µ â”‚ â”‚ è³‡æ–™æ¸…æ´— â”‚ â”‚ æµç¨‹ç¯„æœ¬ â”‚ â”‚ å“¡å·¥æŸ¥è©¢ â”‚           â”‚
â”‚  â”‚  æ¨¡çµ„    â”‚ â”‚  æ¨¡çµ„    â”‚ â”‚  æ¨¡çµ„    â”‚ â”‚ Dashboardâ”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚ è³‡æ ¼æª¢æ ¸ â”‚ â”‚ åˆ°æœŸæé†’ â”‚                                      â”‚
â”‚  â”‚  æ¨¡çµ„    â”‚ â”‚  æ¨¡çµ„    â”‚                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Core Services Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ DataProcessor  â”‚  â”‚ ColumnMatcher  â”‚  â”‚ RuleEngine     â”‚    â”‚
â”‚  â”‚ (pandas)       â”‚  â”‚ (difflib)      â”‚  â”‚ (æ¢ä»¶åˆ¤æ–·)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Data Layer                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ SQLite DB      â”‚  â”‚ JSON Config    â”‚  â”‚ File I/O       â”‚    â”‚
â”‚  â”‚ (å“¡å·¥è³‡æ–™)     â”‚  â”‚ (ç¯„æœ¬/è¨­å®š)    â”‚  â”‚ (Excel/CSV)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      AI Layer (Optional)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Gemini API Client (åƒ…åœ¨éœ€è¦æ™‚å‘¼å«)                      â”‚    â”‚
â”‚  â”‚ - è¤‡é›œè³‡æ ¼åˆ¤æ–·                                          â”‚    â”‚
â”‚  â”‚ - è‡ªç„¶èªè¨€æŸ¥è©¢ (é¸ç”¨)                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ç›®éŒ„çµæ§‹

```
hr_data_tool/
â”œâ”€â”€ app.py                      # Streamlit ä¸»ç¨‹å¼å…¥å£
â”œâ”€â”€ requirements.txt            # Python ä¾è³´
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.json           # å…¨åŸŸè¨­å®š
â”‚   â””â”€â”€ api_config.json         # Gemini API è¨­å®š (gitignore)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ hr_database.db          # SQLite è³‡æ–™åº«
â”‚   â””â”€â”€ templates/              # ä½¿ç”¨è€…ç¯„æœ¬
â”‚       â”œâ”€â”€ column_mappings/    # æ¬„ä½æ˜ å°„ç¯„æœ¬
â”‚       â”œâ”€â”€ workflows/          # è™•ç†æµç¨‹ç¯„æœ¬
â”‚       â””â”€â”€ rules/              # è¦å‰‡ç¯„æœ¬
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ m1_report_merger.py     # æ¨¡çµ„1: å ±è¡¨åˆä½µ
â”‚   â”œâ”€â”€ m2_data_cleaner.py      # æ¨¡çµ„2: è³‡æ–™æ¸…æ´—
â”‚   â”œâ”€â”€ m3_workflow_builder.py  # æ¨¡çµ„3: æµç¨‹ç¯„æœ¬
â”‚   â”œâ”€â”€ m4_employee_dashboard.py # æ¨¡çµ„4: å“¡å·¥æŸ¥è©¢
â”‚   â”œâ”€â”€ m5_qualification_check.py # æ¨¡çµ„5: è³‡æ ¼æª¢æ ¸
â”‚   â””â”€â”€ m6_reminder_system.py   # æ¨¡çµ„6: åˆ°æœŸæé†’
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processor.py       # è³‡æ–™è™•ç†æ ¸å¿ƒ
â”‚   â”œâ”€â”€ column_matcher.py       # æ¬„ä½æ™ºèƒ½æ¯”å°
â”‚   â”œâ”€â”€ rule_engine.py          # è¦å‰‡å¼•æ“
â”‚   â”œâ”€â”€ db_manager.py           # SQLite ç®¡ç†
â”‚   â””â”€â”€ ai_client.py            # Gemini API å°è£
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_handler.py         # æª”æ¡ˆè®€å¯«
â”‚   â”œâ”€â”€ validators.py           # è³‡æ–™é©—è­‰
â”‚   â””â”€â”€ formatters.py           # æ ¼å¼åŒ–å·¥å…·
â””â”€â”€ tests/
    â”œâ”€â”€ test_data/              # æ¸¬è©¦è³‡æ–™ (Excel æª”æ¡ˆ)
    â””â”€â”€ test_modules.py         # å–®å…ƒæ¸¬è©¦
```

---

## 3. åŠŸèƒ½æ¨¡çµ„è©³ç´°è¨­è¨ˆ

### 3.1 æ¨¡çµ„1: å ±è¡¨åˆä½µå™¨ (Report Merger)

**è§£æ±ºå•é¡Œ**: 8å¼µå ±è¡¨æ¬„ä½ä¸çµ±ä¸€ï¼Œéœ€æ•´åˆæˆä¸€å¼µ

#### 3.1.1 åŠŸèƒ½éœ€æ±‚
- æ”¯æ´å¤šæª”æ¡ˆä¸Šå‚³ (Excel/CSV)
- è‡ªå‹•åµæ¸¬ç›¸ä¼¼æ¬„ä½åç¨± (fuzzy matching)
- è¦–è¦ºåŒ–æ¬„ä½å°æ‡‰ä»‹é¢ (æ‹–æ‹‰å¼)
- å„²å­˜/è¼‰å…¥æ¬„ä½æ˜ å°„ç¯„æœ¬
- åˆä½µæ–¹å¼é¸æ“‡ (å‚ç›´å †ç–Š/æ°´å¹³åˆä½µ/ä¾ Key åˆä½µ)
- é‡è¤‡å€¼è™•ç†é¸é …

#### 3.1.2 æ ¸å¿ƒé‚è¼¯

```python
# core/column_matcher.py
from difflib import SequenceMatcher

class ColumnMatcher:
    def __init__(self, threshold: float = 0.6):
        self.threshold = threshold
    
    def find_similar_columns(self, col1_list: list, col2_list: list) -> dict:
        """
        æ‰¾å‡ºå…©ä»½å ±è¡¨ä¸­ç›¸ä¼¼çš„æ¬„ä½
        å›å‚³: {col1_name: (col2_name, similarity_score)}
        """
        matches = {}
        for col1 in col1_list:
            best_match = None
            best_score = 0
            for col2 in col2_list:
                score = SequenceMatcher(None, col1.lower(), col2.lower()).ratio()
                if score > best_score and score >= self.threshold:
                    best_score = score
                    best_match = col2
            if best_match:
                matches[col1] = (best_match, best_score)
        return matches
    
    def suggest_standard_name(self, column_names: list) -> str:
        """
        æ ¹æ“šå¸¸è¦‹ HR æ¬„ä½åç¨±ï¼Œå»ºè­°æ¨™æº–åŒ–åç¨±
        """
        standard_mappings = {
            'å·¥è™Ÿ': ['å“¡å·¥ç·¨è™Ÿ', 'EmpID', 'ID', 'å·¥è™Ÿ', 'ç·¨è™Ÿ', 'EmployeeID'],
            'å§“å': ['å§“å', 'Name', 'å“¡å·¥å§“å', 'EmpName'],
            'éƒ¨é–€': ['éƒ¨é–€', 'Dept', 'Department', 'éƒ¨é–€åç¨±', 'å–®ä½'],
            'åˆ°è·æ—¥': ['åˆ°è·æ—¥', 'å ±åˆ°æ—¥', 'HireDate', 'å…¥è·æ—¥æœŸ'],
            # ... æ›´å¤šæ¨™æº–æ¬„ä½
        }
        for standard, variants in standard_mappings.items():
            for name in column_names:
                if any(v.lower() in name.lower() for v in variants):
                    return standard
        return column_names[0]  # é è¨­ç”¨ç¬¬ä¸€å€‹
```

#### 3.1.3 UI è¨­è¨ˆ

```python
# modules/m1_report_merger.py
import streamlit as st
import pandas as pd
from core.column_matcher import ColumnMatcher

def render():
    st.header("ğŸ“Š å ±è¡¨åˆä½µå™¨")
    
    # Step 1: ä¸Šå‚³æª”æ¡ˆ
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³å ±è¡¨ (å¯å¤šé¸)", 
        type=['xlsx', 'xls', 'csv'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        # Step 2: è®€å–ä¸¦é¡¯ç¤ºå„æª”æ¡ˆæ¬„ä½
        dataframes = {}
        for f in uploaded_files:
            df = pd.read_excel(f) if f.name.endswith(('xlsx', 'xls')) else pd.read_csv(f)
            dataframes[f.name] = df
            st.write(f"**{f.name}**: {len(df)} ç­†, æ¬„ä½: {list(df.columns)}")
        
        # Step 3: æ¬„ä½æ˜ å°„è¨­å®š
        st.subheader("æ¬„ä½å°æ‡‰è¨­å®š")
        
        # è¼‰å…¥/å„²å­˜ç¯„æœ¬
        col1, col2 = st.columns(2)
        with col1:
            template_name = st.text_input("ç¯„æœ¬åç¨±")
        with col2:
            if st.button("å„²å­˜ç¯„æœ¬"):
                # å„²å­˜æ˜ å°„è¨­å®šåˆ° JSON
                pass
        
        # è‡ªå‹•å»ºè­° + æ‰‹å‹•èª¿æ•´
        matcher = ColumnMatcher()
        # ... é¡¯ç¤ºæ˜ å°„è¡¨æ ¼ï¼Œè®“ä½¿ç”¨è€…èª¿æ•´
        
        # Step 4: åˆä½µé¸é …
        merge_method = st.radio(
            "åˆä½µæ–¹å¼",
            ["å‚ç›´å †ç–Š (Union)", "ä¾ Key åˆä½µ (Join)", "æ°´å¹³ä¸²æ¥ (Concat)"]
        )
        
        if merge_method == "ä¾ Key åˆä½µ (Join)":
            key_column = st.selectbox("é¸æ“‡åˆä½µ Key", options=["å·¥è™Ÿ", "å§“å", "èº«åˆ†è­‰å­—è™Ÿ"])
            join_type = st.selectbox("Join é¡å‹", options=["inner", "outer", "left", "right"])
        
        # Step 5: åŸ·è¡Œåˆä½µ
        if st.button("ğŸ”„ åŸ·è¡Œåˆä½µ", type="primary"):
            # åŸ·è¡Œåˆä½µé‚è¼¯
            result_df = merge_dataframes(dataframes, mapping, merge_method)
            st.success(f"åˆä½µå®Œæˆ! å…± {len(result_df)} ç­†è³‡æ–™")
            
            # é è¦½çµæœ
            st.dataframe(result_df.head(20))
            
            # ä¸‹è¼‰æŒ‰éˆ•
            st.download_button(
                "ğŸ’¾ ä¸‹è¼‰åˆä½µçµæœ",
                data=result_df.to_excel(index=False),
                file_name="merged_report.xlsx"
            )
```

#### 3.1.4 AI ä½¿ç”¨: âŒ ä¸éœ€è¦
ç´” Python è¦å‰‡å³å¯è™•ç†ã€‚

---

### 3.2 æ¨¡çµ„2: è³‡æ–™æ¸…æ´—å™¨ (Data Cleaner)

**è§£æ±ºå•é¡Œ**: Raw Data æ¢³ç†æˆå¯ç”¨è³‡è¨Šï¼Œå…¬å¼/VBA é‡æ–°æ¬„ä½æœƒå‡ºéŒ¯

#### 3.2.1 åŠŸèƒ½éœ€æ±‚
- å‹•æ…‹æ¬„ä½åµæ¸¬ (ç”¨ç‰¹å¾µè€Œéä½ç½®)
- è³‡æ–™é¡å‹è‡ªå‹•è­˜åˆ¥èˆ‡è½‰æ›
- å¸¸è¦‹æ¸…æ´—æ“ä½œ (å»ç©ºç™½/æ—¥æœŸçµ±ä¸€/é‡è¤‡å€¼è™•ç†)
- æ¸…æ´—æ­¥é©Ÿå¯è¦–åŒ– & å¯å›æº¯
- å„²å­˜ç‚ºæ¸…æ´—ç¯„æœ¬

#### 3.2.2 æ ¸å¿ƒé‚è¼¯

```python
# core/data_processor.py
import pandas as pd
from typing import List, Dict, Callable

class DataProcessor:
    def __init__(self, df: pd.DataFrame):
        self.df = df.copy()
        self.history = []  # æ“ä½œæ­·å²ï¼Œæ”¯æ´å›æº¯
    
    def find_column_by_keywords(self, keywords: List[str]) -> str:
        """å‹•æ…‹å°‹æ‰¾æ¬„ä½ï¼Œä¸ä¾è³´å›ºå®šä½ç½®"""
        for col in self.df.columns:
            col_lower = str(col).lower()
            if any(kw.lower() in col_lower for kw in keywords):
                return col
        return None
    
    def detect_column_type(self, column: str) -> str:
        """åµæ¸¬æ¬„ä½è³‡æ–™é¡å‹"""
        sample = self.df[column].dropna().head(100)
        
        # å˜—è©¦æ—¥æœŸ
        try:
            pd.to_datetime(sample)
            return 'datetime'
        except:
            pass
        
        # å˜—è©¦æ•¸å­—
        try:
            pd.to_numeric(sample)
            return 'numeric'
        except:
            pass
        
        return 'string'
    
    def apply_cleaning_step(self, step: Dict):
        """åŸ·è¡Œå–®ä¸€æ¸…æ´—æ­¥é©Ÿ"""
        action = step['action']
        column = step.get('column')
        
        # è¨˜éŒ„æ­·å²
        self.history.append({
            'step': step,
            'before_shape': self.df.shape
        })
        
        if action == 'trim_whitespace':
            self.df[column] = self.df[column].astype(str).str.strip()
        
        elif action == 'unify_date_format':
            target_format = step.get('format', '%Y-%m-%d')
            self.df[column] = pd.to_datetime(self.df[column]).dt.strftime(target_format)
        
        elif action == 'remove_duplicates':
            subset = step.get('subset', None)
            keep = step.get('keep', 'first')
            self.df = self.df.drop_duplicates(subset=subset, keep=keep)
        
        elif action == 'fill_na':
            fill_value = step.get('value', '')
            self.df[column] = self.df[column].fillna(fill_value)
        
        elif action == 'split_column':
            delimiter = step.get('delimiter', ',')
            new_columns = step.get('new_columns', [])
            splits = self.df[column].str.split(delimiter, expand=True)
            for i, new_col in enumerate(new_columns):
                if i < splits.shape[1]:
                    self.df[new_col] = splits[i]
        
        elif action == 'rename_column':
            new_name = step.get('new_name')
            self.df = self.df.rename(columns={column: new_name})
        
        return self.df
    
    def undo(self):
        """å›æº¯ä¸Šä¸€æ­¥æ“ä½œ"""
        if self.history:
            # å¯¦éš›å¯¦ä½œéœ€è¦å„²å­˜ snapshot æˆ–åå‘æ“ä½œ
            pass
```

#### 3.2.3 UI è¨­è¨ˆ

```python
# modules/m2_data_cleaner.py
import streamlit as st

def render():
    st.header("ğŸ§¹ è³‡æ–™æ¸…æ´—å™¨")
    
    uploaded_file = st.file_uploader("ä¸Šå‚³åŸå§‹è³‡æ–™", type=['xlsx', 'csv'])
    
    if uploaded_file:
        df = load_data(uploaded_file)
        processor = DataProcessor(df)
        
        # é¡¯ç¤ºè³‡æ–™é è¦½ & æ¬„ä½è³‡è¨Š
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("è³‡æ–™é è¦½")
            st.dataframe(df.head(10))
        
        with col2:
            st.subheader("æ¬„ä½åˆ†æ")
            for col in df.columns:
                dtype = processor.detect_column_type(col)
                null_count = df[col].isna().sum()
                st.write(f"**{col}**: {dtype}, ç©ºå€¼: {null_count}")
        
        # æ¸…æ´—æ­¥é©Ÿè¨­å®š
        st.subheader("æ¸…æ´—æ­¥é©Ÿ")
        
        step_type = st.selectbox("é¸æ“‡æ“ä½œ", [
            "å»é™¤å‰å¾Œç©ºç™½", "çµ±ä¸€æ—¥æœŸæ ¼å¼", "ç§»é™¤é‡è¤‡å€¼",
            "å¡«å…¥ç©ºå€¼", "åˆ†å‰²æ¬„ä½", "é‡æ–°å‘½åæ¬„ä½",
            "è½‰æ›è³‡æ–™é¡å‹", "æ¢ä»¶ç¯©é¸"
        ])
        
        # æ ¹æ“šé¸æ“‡é¡¯ç¤ºå°æ‡‰è¨­å®š
        if step_type == "å»é™¤å‰å¾Œç©ºç™½":
            target_col = st.selectbox("é¸æ“‡æ¬„ä½", df.columns)
            if st.button("â• åŠ å…¥æ­¥é©Ÿ"):
                st.session_state.cleaning_steps.append({
                    'action': 'trim_whitespace',
                    'column': target_col
                })
        
        # ... å…¶ä»–æ­¥é©Ÿè¨­å®š
        
        # é¡¯ç¤ºå·²åŠ å…¥çš„æ­¥é©Ÿ
        st.subheader("å¾…åŸ·è¡Œæ­¥é©Ÿ")
        for i, step in enumerate(st.session_state.get('cleaning_steps', [])):
            st.write(f"{i+1}. {step}")
        
        # åŸ·è¡Œæ¸…æ´—
        if st.button("ğŸš€ åŸ·è¡Œæ¸…æ´—", type="primary"):
            for step in st.session_state.cleaning_steps:
                processor.apply_cleaning_step(step)
            
            st.success("æ¸…æ´—å®Œæˆ!")
            st.dataframe(processor.df.head(20))
```

#### 3.2.4 AI ä½¿ç”¨: âŒ ä¸éœ€è¦

---

### 3.3 æ¨¡çµ„3: æµç¨‹ç¯„æœ¬ç³»çµ± (Workflow Builder)

**è§£æ±ºå•é¡Œ**: è³‡æ–™æ¯”å°ã€æ•´åˆçš„é‡è¤‡æ€§å·¥ä½œï¼Œå ±è¡¨æ‹†åˆ†å¾Œéœ€åˆä½µ

#### 3.3.1 åŠŸèƒ½éœ€æ±‚
- è¦–è¦ºåŒ–æµç¨‹å»ºæ§‹ (Step-by-Step)
- å„²å­˜/è¼‰å…¥æµç¨‹ç¯„æœ¬
- ä¸€éµåŸ·è¡Œå·²å„²å­˜æµç¨‹
- æ”¯æ´æ’ç¨‹åŸ·è¡Œ (é¸ç”¨)
- æµç¨‹åŸ·è¡Œæ—¥èªŒ

#### 3.3.2 è³‡æ–™çµæ§‹

```json
// data/templates/workflows/monthly_report_flow.json
{
  "flow_id": "flow_001",
  "flow_name": "æœˆå ±æ•´åˆæµç¨‹",
  "description": "æ¯æœˆæ•´åˆå„éƒ¨é–€å®Œè¨“å ±è¡¨",
  "created_at": "2025-01-02",
  "steps": [
    {
      "step_id": 1,
      "action": "import",
      "config": {
        "source_type": "folder",
        "path": "C:/HR_Reports/2025/Jan",
        "file_pattern": "*.xlsx"
      }
    },
    {
      "step_id": 2,
      "action": "apply_column_mapping",
      "config": {
        "template_name": "training_report_mapping"
      }
    },
    {
      "step_id": 3,
      "action": "merge",
      "config": {
        "method": "union",
        "remove_duplicates": true,
        "duplicate_key": "å·¥è™Ÿ"
      }
    },
    {
      "step_id": 4,
      "action": "calculate",
      "config": {
        "new_column": "å®Œè¨“ç‡",
        "formula": "å®Œè¨“æ™‚æ•¸ / æ‡‰å®Œè¨“æ™‚æ•¸ * 100"
      }
    },
    {
      "step_id": 5,
      "action": "export",
      "config": {
        "filename": "å®Œè¨“å ±è¡¨å½™ç¸½_{date}.xlsx",
        "path": "C:/HR_Reports/Output"
      }
    }
  ]
}
```

#### 3.3.3 AI ä½¿ç”¨: âŒ ä¸éœ€è¦

---

### 3.4 æ¨¡çµ„4: å“¡å·¥æŸ¥è©¢ Dashboard (Employee Dashboard)

**è§£æ±ºå•é¡Œ**: æŸ¥è©¢å“¡å·¥æ­·ç¨‹éœ€è·¨ç³»çµ±ã€è¤‡è£½è²¼ä¸Šæ‰èƒ½æœ‰å…¨è²Œ

#### 3.4.1 åŠŸèƒ½éœ€æ±‚
- æ•´åˆå¤šè³‡æ–™æºåˆ°æœ¬åœ° SQLite
- ä»¥å·¥è™Ÿç‚º Key ä¸²æ¥æ‰€æœ‰è³‡æ–™
- å–®ä¸€æŸ¥è©¢ä»‹é¢é¡¯ç¤ºå®Œæ•´è³‡è¨Š
- æ”¯æ´æ¨¡ç³Šæœå°‹ (å§“å/å·¥è™Ÿ)
- è³‡æ–™å®šæœŸåŒ¯å…¥æ©Ÿåˆ¶

#### 3.4.2 è³‡æ–™åº« Schema

```sql
-- core/db_manager.py æœƒå»ºç«‹ä»¥ä¸‹è¡¨æ ¼

-- å“¡å·¥ä¸»æª”
CREATE TABLE employees (
    emp_id TEXT PRIMARY KEY,      -- å·¥è™Ÿ
    name TEXT NOT NULL,
    id_number TEXT,               -- èº«åˆ†è­‰å­—è™Ÿ (åŠ å¯†å„²å­˜)
    department TEXT,
    hire_date DATE,
    status TEXT,                  -- åœ¨è·/é›¢è·
    updated_at TIMESTAMP
);

-- ç¸¾æ•ˆç´€éŒ„
CREATE TABLE performance (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    emp_id TEXT,
    year INTEGER,
    rating TEXT,                  -- A/B+/B/C
    score REAL,
    updated_at TIMESTAMP,
    FOREIGN KEY (emp_id) REFERENCES employees(emp_id)
);

-- è¨“ç·´ç´€éŒ„
CREATE TABLE training (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    emp_id TEXT,
    course_name TEXT,
    course_type TEXT,             -- å¿…ä¿®/é¸ä¿®
    hours REAL,
    completion_date DATE,
    updated_at TIMESTAMP,
    FOREIGN KEY (emp_id) REFERENCES employees(emp_id)
);

-- é›¢è·ç´€éŒ„ (ç”¨æ–¼å›ä»»åˆ¤æ–·)
CREATE TABLE separation (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    emp_id TEXT,
    separation_date DATE,
    separation_type TEXT,         -- è‡ªé¡˜é›¢è·/è³‡é£/é€€ä¼‘
    reason TEXT,
    blacklist BOOLEAN DEFAULT FALSE,
    updated_at TIMESTAMP,
    FOREIGN KEY (emp_id) REFERENCES employees(emp_id)
);

-- è³‡æ–™åŒ¯å…¥æ—¥èªŒ
CREATE TABLE import_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_name TEXT,
    import_date TIMESTAMP,
    record_count INTEGER,
    status TEXT
);
```

#### 3.4.3 UI è¨­è¨ˆ

```python
# modules/m4_employee_dashboard.py
import streamlit as st
from core.db_manager import DBManager

def render():
    st.header("ğŸ‘¤ å“¡å·¥è³‡æ–™æŸ¥è©¢")
    
    db = DBManager()
    
    # æœå°‹å€
    search_input = st.text_input("ğŸ” è¼¸å…¥å·¥è™Ÿæˆ–å§“å")
    
    if search_input:
        employees = db.search_employee(search_input)
        
        if employees:
            selected = st.selectbox(
                "é¸æ“‡å“¡å·¥",
                options=employees,
                format_func=lambda x: f"{x['emp_id']} - {x['name']} ({x['department']})"
            )
            
            if selected:
                emp_id = selected['emp_id']
                
                # åŸºæœ¬è³‡æ–™å¡
                st.subheader("ğŸ“‹ åŸºæœ¬è³‡æ–™")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å·¥è™Ÿ", emp_id)
                with col2:
                    st.metric("å§“å", selected['name'])
                with col3:
                    st.metric("éƒ¨é–€", selected['department'])
                
                st.write(f"åˆ°è·æ—¥: {selected['hire_date']} | ç‹€æ…‹: {selected['status']}")
                
                # ç¸¾æ•ˆæ­·ç¨‹
                st.subheader("ğŸ“ˆ ç¸¾æ•ˆæ­·ç¨‹")
                perf_records = db.get_performance_history(emp_id)
                if perf_records:
                    perf_df = pd.DataFrame(perf_records)
                    st.dataframe(perf_df, hide_index=True)
                else:
                    st.info("ç„¡ç¸¾æ•ˆç´€éŒ„")
                
                # è¨“ç·´ç´€éŒ„
                st.subheader("ğŸ“ è¨“ç·´ç´€éŒ„")
                training_records = db.get_training_history(emp_id)
                if training_records:
                    total_hours = sum(r['hours'] for r in training_records)
                    st.metric("ç¸½å®Œè¨“æ™‚æ•¸", f"{total_hours} å°æ™‚")
                    st.dataframe(pd.DataFrame(training_records), hide_index=True)
                
                # é›¢è·ç´€éŒ„ (è‹¥æœ‰)
                sep_record = db.get_separation_record(emp_id)
                if sep_record:
                    st.subheader("ğŸšª é›¢è·ç´€éŒ„")
                    st.warning(f"é›¢è·æ—¥æœŸ: {sep_record['separation_date']}, åŸå› : {sep_record['reason']}")
                    if sep_record['blacklist']:
                        st.error("âš ï¸ æ­¤å“¡å·¥å·²åˆ—å…¥é»‘åå–®")
        else:
            st.warning("æŸ¥ç„¡æ­¤å“¡å·¥")
    
    # å´é‚Šæ¬„: è³‡æ–™åŒ¯å…¥
    with st.sidebar:
        st.subheader("ğŸ“¥ è³‡æ–™åŒ¯å…¥")
        
        import_type = st.selectbox("é¸æ“‡åŒ¯å…¥é¡å‹", [
            "å“¡å·¥ä¸»æª” (SAP)", "ç¸¾æ•ˆè³‡æ–™", "è¨“ç·´ç´€éŒ„", "é›¢è·ç´€éŒ„"
        ])
        
        upload = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ", type=['xlsx', 'csv'])
        
        if upload and st.button("åŸ·è¡ŒåŒ¯å…¥"):
            # åŸ·è¡ŒåŒ¯å…¥é‚è¼¯
            result = db.import_data(import_type, upload)
            st.success(f"åŒ¯å…¥å®Œæˆ! å…± {result['count']} ç­†")
```

#### 3.4.4 AI ä½¿ç”¨: âŒ ä¸éœ€è¦

---

### 3.5 æ¨¡çµ„5: è³‡æ ¼æª¢æ ¸å™¨ (Qualification Checker)

**è§£æ±ºå•é¡Œ**: é›¢è·å›ä»»è³‡æ ¼éœ€æ¯”å°å¤šç³»çµ±è³‡æ–™ï¼ˆäººæ‰ç¶²ã€HCPã€SAPã€é»‘åå–®ï¼‰

#### 3.5.1 åŠŸèƒ½éœ€æ±‚
- è¼¸å…¥å§“å/èº«åˆ†è­‰é€²è¡Œæª¢æ ¸
- è‡ªå‹•åŸ·è¡Œè¦å‰‡æª¢æ ¸ (Python)
- è¤‡é›œ/ä¾‹å¤–æƒ…æ³å‘¼å« AI ç¶œåˆåˆ¤æ–·
- ç”¢ç”Ÿæª¢æ ¸å ±å‘Š (å¯åŒ¯å‡º)

#### 3.5.2 æª¢æ ¸æµç¨‹

```
è¼¸å…¥: å§“å + èº«åˆ†è­‰å­—è™Ÿ
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: é»‘åå–®æ¯”å° â”‚ â—„â”€â”€ Python è¦å‰‡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ è‹¥åœ¨é»‘åå–® â†’ ç›´æ¥æ‹’çµ•
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: HCP åœ¨è·æŸ¥ â”‚ â—„â”€â”€ Python è¦å‰‡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ è‹¥å…¶ä»–å…¬å¸åœ¨è· â†’ æ¨™è¨˜è­¦ç¤º
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: æ­·å²ç¸¾æ•ˆæŸ¥ â”‚ â—„â”€â”€ Python è¦å‰‡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ æå–è€ƒç¸¾ç´€éŒ„
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: é›¢è·åŸå› æŸ¥ â”‚ â—„â”€â”€ Python è¦å‰‡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: ç¶œåˆåˆ¤æ–·              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ è¦å‰‡æ˜ç¢º? (å…¨éƒ¨ PASS)   â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â”‚ Yes          â”‚ No     â”‚
â”‚      â–¼              â–¼        â”‚
â”‚  [ç›´æ¥é€šé]    [å‘¼å« Gemini] â”‚ â—„â”€â”€ åƒ…æ­¤æ­¥é©Ÿéœ€è¦ AI
â”‚                åˆ¤æ–·ä¾‹å¤–æƒ…æ³   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    è¼¸å‡ºæª¢æ ¸å ±å‘Š
```

#### 3.5.3 æ ¸å¿ƒé‚è¼¯

```python
# modules/m5_qualification_check.py
from core.rule_engine import RuleEngine
from core.ai_client import GeminiClient
from core.db_manager import DBManager

class QualificationChecker:
    def __init__(self):
        self.db = DBManager()
        self.rule_engine = RuleEngine()
        self.ai_client = GeminiClient()  # å»¶é²åˆå§‹åŒ–
    
    def check(self, name: str, id_number: str) -> dict:
        result = {
            'name': name,
            'checks': [],
            'overall_status': 'PENDING',
            'ai_used': False,
            'ai_recommendation': None
        }
        
        # Step 1: é»‘åå–®
        blacklist_check = self.db.check_blacklist(id_number)
        result['checks'].append({
            'item': 'é»‘åå–®æ¯”å°',
            'status': 'FAIL' if blacklist_check else 'PASS',
            'detail': 'åˆ—æ–¼é»‘åå–®ä¸­' if blacklist_check else 'æœªåœ¨é»‘åå–®'
        })
        
        if blacklist_check:
            result['overall_status'] = 'REJECTED'
            return result
        
        # Step 2: HCP åœ¨è·æŸ¥è©¢
        hcp_status = self.db.check_hcp_employment(id_number)
        result['checks'].append({
            'item': 'HCP å„å…¬å¸åœ¨è·ç‹€æ…‹',
            'status': 'WARNING' if hcp_status else 'PASS',
            'detail': f"åœ¨ {hcp_status} ä»»è·ä¸­" if hcp_status else 'ç„¡å…¶ä»–å…¬å¸åœ¨è·ç´€éŒ„'
        })
        
        # Step 3: æ­·å²ç¸¾æ•ˆ
        perf_history = self.db.get_performance_by_id(id_number)
        low_perf = [p for p in perf_history if p['rating'] in ['C', 'D']]
        result['checks'].append({
            'item': 'æ­·å²ç¸¾æ•ˆç´€éŒ„',
            'status': 'WARNING' if low_perf else 'PASS',
            'detail': f"æ›¾æœ‰ {len(low_perf)} æ¬¡ä½ç¸¾æ•ˆç´€éŒ„" if low_perf else 'ç¸¾æ•ˆç´€éŒ„è‰¯å¥½'
        })
        
        # Step 4: é›¢è·åŸå› 
        sep_record = self.db.get_separation_by_id(id_number)
        if sep_record:
            result['checks'].append({
                'item': 'é›¢è·ç´€éŒ„',
                'status': 'INFO',
                'detail': f"é›¢è·æ—¥æœŸ: {sep_record['date']}, åŸå› : {sep_record['reason']}"
            })
        
        # Step 5: ç¶œåˆåˆ¤æ–·
        warnings = [c for c in result['checks'] if c['status'] == 'WARNING']
        
        if not warnings:
            # å…¨éƒ¨ PASSï¼Œä¸éœ€è¦ AI
            result['overall_status'] = 'APPROVED'
        else:
            # æœ‰è­¦ç¤ºé …ç›®ï¼Œå‘¼å« AI åˆ¤æ–·
            result['ai_used'] = True
            result['ai_recommendation'] = self._get_ai_judgment(result)
            result['overall_status'] = 'REVIEW_REQUIRED'
        
        return result
    
    def _get_ai_judgment(self, check_result: dict) -> str:
        """å‘¼å« Gemini API é€²è¡Œç¶œåˆåˆ¤æ–·"""
        prompt = f"""
        ä½ æ˜¯ HR è³‡æ·±å°ˆå“¡ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æª¢æ ¸çµæœï¼Œçµ¦å‡ºé›¢è·å›ä»»è³‡æ ¼çš„å»ºè­°ï¼š
        
        ç”³è«‹äºº: {check_result['name']}
        æª¢æ ¸é …ç›®:
        {self._format_checks(check_result['checks'])}
        
        è«‹çµ¦å‡º:
        1. æ˜¯å¦å»ºè­°æ ¸å‡†å›ä»» (å»ºè­°æ ¸å‡† / å»ºè­°æ‹’çµ• / éœ€ä¸»ç®¡é¢è«‡è©•ä¼°)
        2. ç†ç”±èªªæ˜ (2-3 å¥è©±)
        3. è‹¥æœ‰ç–‘æ…®ï¼Œå»ºè­°é€²ä¸€æ­¥ç¢ºèªçš„äº‹é …
        
        è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œèªæ°£å°ˆæ¥­ä½†ä¸è¦å¤ªåˆ¶å¼ã€‚
        """
        
        return self.ai_client.generate(prompt)
```

#### 3.5.4 AI ä½¿ç”¨: âš ï¸ åƒ…åœ¨æœ‰è­¦ç¤ºé …ç›®æ™‚å‘¼å«
- å…¨éƒ¨ PASS â†’ ä¸å‘¼å« AIï¼Œç›´æ¥é€šé
- æœ‰ WARNING â†’ å‘¼å« Gemini ç¶œåˆåˆ¤æ–·

#### 3.5.5 æˆæœ¬æ§åˆ¶

```python
# core/ai_client.py
class GeminiClient:
    def __init__(self):
        self.api_key = self._load_api_key()
        self.call_count = 0
        self.last_call_time = None
    
    def generate(self, prompt: str, confirm: bool = True) -> str:
        """
        å‘¼å« Gemini API
        confirm: è‹¥ç‚º Trueï¼Œåœ¨ UI å±¤æœƒå…ˆè©¢å•ä½¿ç”¨è€…ç¢ºèª
        """
        if confirm:
            # é€™å€‹ flag æœƒè®“ UI å±¤é¡¯ç¤ºç¢ºèªå°è©±æ¡†
            pass
        
        # å¯¦éš›å‘¼å« API
        import google.generativeai as genai
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')  # ä½¿ç”¨è¼ƒä¾¿å®œçš„æ¨¡å‹
        response = model.generate_content(prompt)
        
        self.call_count += 1
        return response.text
```

---

### 3.6 æ¨¡çµ„6: åˆ°æœŸæé†’ç³»çµ± (Reminder System)

**è§£æ±ºå•é¡Œ**: è©¦ç”¨æœŸæ»¿èª¿è–ªè¿½è¹¤ï¼ŒSAP ç„¡è¨»æ˜è™•ï¼Œéœ€äººå·¥è¨˜æ†¶æˆ–æ¯æœˆæ’ˆå ±è¡¨æ¯”å°

#### 3.6.1 åŠŸèƒ½éœ€æ±‚
- åŒ¯å…¥æ–°é€²äººå“¡åå–®
- è‡ªå‹•è¨ˆç®—è©¦ç”¨æœŸæ»¿æ—¥
- Dashboard é¡¯ç¤ºæœ¬æœˆ/ä¸‹æœˆå¾…è™•ç†æ¸…å–®
- æ¨™è¨˜å·²è™•ç†ç‹€æ…‹
- åŒ¯å‡ºæé†’æ¸…å–® (Email/Excel)

#### 3.6.2 è³‡æ–™çµæ§‹

```sql
-- è¿½è¹¤é …ç›®è¡¨
CREATE TABLE reminders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    emp_id TEXT,
    reminder_type TEXT,           -- 'probation' / 'contract_renewal' / 'custom'
    start_date DATE,
    due_date DATE,
    status TEXT DEFAULT 'pending', -- 'pending' / 'completed' / 'cancelled'
    notes TEXT,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.6.3 UI è¨­è¨ˆ

```python
# modules/m6_reminder_system.py
import streamlit as st
from datetime import datetime, timedelta

def render():
    st.header("â° åˆ°æœŸæé†’ç³»çµ±")
    
    # åˆ‡æ›è¦–åœ–
    view = st.radio("æª¢è¦–", ["æœ¬æœˆå¾…è™•ç†", "ä¸‹æœˆé å‘Š", "å…¨éƒ¨é …ç›®"], horizontal=True)
    
    db = DBManager()
    today = datetime.now().date()
    
    if view == "æœ¬æœˆå¾…è™•ç†":
        month_end = today.replace(day=28) + timedelta(days=4)
        month_end = month_end.replace(day=1) - timedelta(days=1)
        items = db.get_reminders_by_range(today, month_end, status='pending')
    
    elif view == "ä¸‹æœˆé å‘Š":
        next_month_start = (today.replace(day=1) + timedelta(days=32)).replace(day=1)
        next_month_end = (next_month_start + timedelta(days=32)).replace(day=1) - timedelta(days=1)
        items = db.get_reminders_by_range(next_month_start, next_month_end)
    
    else:
        items = db.get_all_reminders()
    
    # é¡¯ç¤ºçµ±è¨ˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¾…è™•ç†", len([i for i in items if i['status'] == 'pending']))
    with col2:
        urgent = [i for i in items if (i['due_date'] - today).days <= 7]
        st.metric("7å¤©å…§åˆ°æœŸ", len(urgent), delta_color="inverse")
    with col3:
        st.metric("å·²å®Œæˆ", len([i for i in items if i['status'] == 'completed']))
    
    # å¾…è™•ç†æ¸…å–®
    st.subheader("ğŸ“‹ å¾…è™•ç†æ¸…å–®")
    
    for item in items:
        if item['status'] == 'pending':
            days_left = (item['due_date'] - today).days
            
            with st.container():
                col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
                
                with col1:
                    st.write(f"**{item['emp_id']}** - {item['emp_name']}")
                
                with col2:
                    st.write(f"åˆ°æœŸæ—¥: {item['due_date']}")
                
                with col3:
                    if days_left < 0:
                        st.error(f"å·²é€¾æœŸ {abs(days_left)} å¤©")
                    elif days_left <= 7:
                        st.warning(f"å‰© {days_left} å¤©")
                    else:
                        st.info(f"å‰© {days_left} å¤©")
                
                with col4:
                    if st.button("âœ… å®Œæˆ", key=f"done_{item['id']}"):
                        db.mark_reminder_completed(item['id'])
                        st.rerun()
    
    # æ–°å¢æé†’
    with st.expander("â• æ‰‹å‹•æ–°å¢æé†’"):
        emp_id = st.text_input("å·¥è™Ÿ")
        reminder_type = st.selectbox("é¡å‹", ["è©¦ç”¨æœŸæ»¿", "åˆç´„åˆ°æœŸ", "å…¶ä»–"])
        due_date = st.date_input("åˆ°æœŸæ—¥")
        notes = st.text_area("å‚™è¨»")
        
        if st.button("æ–°å¢"):
            db.add_reminder(emp_id, reminder_type, due_date, notes)
            st.success("æ–°å¢æˆåŠŸ!")
    
    # æ‰¹æ¬¡åŒ¯å…¥
    with st.expander("ğŸ“¥ æ‰¹æ¬¡åŒ¯å…¥æ–°é€²äººå“¡"):
        st.write("ä¸Šå‚³æ–°é€²äººå“¡åå–®ï¼Œè‡ªå‹•è¨ˆç®—è©¦ç”¨æœŸæ»¿æ—¥ (åˆ°è·æ—¥ + 3å€‹æœˆ)")
        
        upload = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ", type=['xlsx', 'csv'], key='batch_import')
        probation_months = st.number_input("è©¦ç”¨æœŸæœˆæ•¸", value=3, min_value=1, max_value=12)
        
        if upload and st.button("åŸ·è¡ŒåŒ¯å…¥"):
            df = pd.read_excel(upload)
            # é©—è­‰å¿…è¦æ¬„ä½
            required = ['å·¥è™Ÿ', 'å§“å', 'åˆ°è·æ—¥']
            # ... åŸ·è¡ŒåŒ¯å…¥
```

#### 3.6.4 AI ä½¿ç”¨: âŒ ä¸éœ€è¦

---

## 4. å…±ç”¨å…ƒä»¶è¨­è¨ˆ

### 4.1 Gemini API å®¢æˆ¶ç«¯

```python
# core/ai_client.py
import os
import json
from datetime import datetime

class GeminiClient:
    def __init__(self, config_path: str = 'config/api_config.json'):
        self.config = self._load_config(config_path)
        self.usage_log = []
    
    def _load_config(self, path: str) -> dict:
        if os.path.exists(path):
            with open(path, 'r') as f:
                return json.load(f)
        return {'api_key': None, 'model': 'gemini-1.5-flash'}
    
    def is_configured(self) -> bool:
        return self.config.get('api_key') is not None
    
    def generate(self, prompt: str, temperature: float = 0.7) -> str:
        """å‘¼å« Gemini API"""
        if not self.is_configured():
            raise ValueError("Gemini API å°šæœªè¨­å®š")
        
        import google.generativeai as genai
        genai.configure(api_key=self.config['api_key'])
        
        model = genai.GenerativeModel(self.config['model'])
        response = model.generate_content(
            prompt,
            generation_config={'temperature': temperature}
        )
        
        # è¨˜éŒ„ä½¿ç”¨
        self.usage_log.append({
            'timestamp': datetime.now().isoformat(),
            'prompt_length': len(prompt),
            'response_length': len(response.text)
        })
        
        return response.text
    
    def get_usage_stats(self) -> dict:
        """å–å¾— API ä½¿ç”¨çµ±è¨ˆ"""
        return {
            'total_calls': len(self.usage_log),
            'total_prompt_chars': sum(l['prompt_length'] for l in self.usage_log),
            'total_response_chars': sum(l['response_length'] for l in self.usage_log)
        }
```

### 4.2 è¨­å®šç®¡ç†

```python
# core/config_manager.py
import json
import os

class ConfigManager:
    def __init__(self, config_dir: str = 'config'):
        self.config_dir = config_dir
        os.makedirs(config_dir, exist_ok=True)
    
    def save_template(self, template_type: str, name: str, data: dict):
        """å„²å­˜ç¯„æœ¬"""
        path = os.path.join(self.config_dir, 'templates', template_type)
        os.makedirs(path, exist_ok=True)
        
        filepath = os.path.join(path, f"{name}.json")
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load_template(self, template_type: str, name: str) -> dict:
        """è¼‰å…¥ç¯„æœ¬"""
        filepath = os.path.join(self.config_dir, 'templates', template_type, f"{name}.json")
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def list_templates(self, template_type: str) -> list:
        """åˆ—å‡ºæ‰€æœ‰ç¯„æœ¬"""
        path = os.path.join(self.config_dir, 'templates', template_type)
        if os.path.exists(path):
            return [f.replace('.json', '') for f in os.listdir(path) if f.endswith('.json')]
        return []
```

---

## 5. æŠ€è¡“è¦æ ¼

### 5.1 é–‹ç™¼ç’°å¢ƒéœ€æ±‚

```
Python >= 3.9
```

### 5.2 ä¾è³´å¥—ä»¶

```txt
# requirements.txt

# GUI
streamlit>=1.28.0

# è³‡æ–™è™•ç†
pandas>=2.0.0
openpyxl>=3.1.0
xlrd>=2.0.0

# è³‡æ–™åº«
# (sqlite3 ç‚º Python å…§å»º)

# AI æ•´åˆ
google-generativeai>=0.3.0

# å…¶ä»–å·¥å…·
python-dateutil>=2.8.0
```

### 5.3 åŸ·è¡ŒæŒ‡ä»¤

```bash
# å®‰è£ä¾è³´
pip install -r requirements.txt

# åŸ·è¡Œæ‡‰ç”¨
streamlit run app.py

# åŸ·è¡Œæ¸¬è©¦
python -m pytest tests/
```

---

## 6. ä¸»ç¨‹å¼å…¥å£

```python
# app.py
import streamlit as st

# é é¢é…ç½®
st.set_page_config(
    page_title="HR è³‡æ–™è™•ç†å·¥å…·",
    page_icon="ğŸ‘¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å´é‚Šæ¬„å°èˆª
st.sidebar.title("ğŸ‘¥ HR è³‡æ–™è™•ç†å·¥å…·")

module = st.sidebar.radio(
    "åŠŸèƒ½æ¨¡çµ„",
    [
        "ğŸ“Š å ±è¡¨åˆä½µå™¨",
        "ğŸ§¹ è³‡æ–™æ¸…æ´—å™¨", 
        "ğŸ”„ æµç¨‹ç¯„æœ¬ç³»çµ±",
        "ğŸ‘¤ å“¡å·¥æŸ¥è©¢",
        "âœ… è³‡æ ¼æª¢æ ¸å™¨",
        "â° åˆ°æœŸæé†’"
    ]
)

# è¼‰å…¥å°æ‡‰æ¨¡çµ„
if module == "ğŸ“Š å ±è¡¨åˆä½µå™¨":
    from modules import m1_report_merger
    m1_report_merger.render()

elif module == "ğŸ§¹ è³‡æ–™æ¸…æ´—å™¨":
    from modules import m2_data_cleaner
    m2_data_cleaner.render()

elif module == "ğŸ”„ æµç¨‹ç¯„æœ¬ç³»çµ±":
    from modules import m3_workflow_builder
    m3_workflow_builder.render()

elif module == "ğŸ‘¤ å“¡å·¥æŸ¥è©¢":
    from modules import m4_employee_dashboard
    m4_employee_dashboard.render()

elif module == "âœ… è³‡æ ¼æª¢æ ¸å™¨":
    from modules import m5_qualification_check
    m5_qualification_check.render()

elif module == "â° åˆ°æœŸæé†’":
    from modules import m6_reminder_system
    m6_reminder_system.render()

# å´é‚Šæ¬„åº•éƒ¨: è¨­å®š & ç‹€æ…‹
st.sidebar.divider()

with st.sidebar.expander("âš™ï¸ ç³»çµ±è¨­å®š"):
    # API è¨­å®š
    api_key = st.text_input("Gemini API Key", type="password")
    if st.button("å„²å­˜ API Key"):
        # å„²å­˜åˆ° config
        pass
    
    # è³‡æ–™åº«ç‹€æ…‹
    st.write("ğŸ“ è³‡æ–™åº«ç‹€æ…‹: å·²é€£æ¥")
    st.write("ğŸ“Š å“¡å·¥è³‡æ–™: 1,234 ç­†")

st.sidebar.caption("ç‰ˆæœ¬ 1.0 | Â© 2025")
```

---

## 7. AI ä½¿ç”¨æ‘˜è¦

| æ¨¡çµ„ | æ˜¯å¦éœ€è¦ AI | èªªæ˜ |
|------|------------|------|
| å ±è¡¨åˆä½µå™¨ | âŒ ä¸éœ€è¦ | difflib + pandas å³å¯ |
| è³‡æ–™æ¸…æ´—å™¨ | âŒ ä¸éœ€è¦ | ç´”è¦å‰‡è™•ç† |
| æµç¨‹ç¯„æœ¬ç³»çµ± | âŒ ä¸éœ€è¦ | JSON ç¯„æœ¬ + åŸ·è¡Œå¼•æ“ |
| å“¡å·¥æŸ¥è©¢ | âŒ ä¸éœ€è¦ | SQLite æŸ¥è©¢ |
| è³‡æ ¼æª¢æ ¸å™¨ | âš ï¸ æ¢ä»¶å¼ | åƒ…æœ‰ WARNING æ™‚å‘¼å« |
| åˆ°æœŸæé†’ | âŒ ä¸éœ€è¦ | æ—¥æœŸè¨ˆç®— + ç‹€æ…‹ç®¡ç† |

**é ä¼° API ç¯€çœ**: 90%+ çš„æ“ä½œä¸éœ€å‘¼å« AI

---

## 8. é–‹ç™¼é †åºå»ºè­°

1. **Phase 1 - æ ¸å¿ƒåŸºç¤** (Week 1-2)
   - [ ] å°ˆæ¡ˆæ¶æ§‹å»ºç«‹
   - [ ] core/db_manager.py
   - [ ] core/data_processor.py
   - [ ] ä¸»ç¨‹å¼å…¥å£ app.py

2. **Phase 2 - é«˜åƒ¹å€¼æ¨¡çµ„** (Week 3-4)
   - [ ] æ¨¡çµ„1: å ±è¡¨åˆä½µå™¨
   - [ ] æ¨¡çµ„6: åˆ°æœŸæé†’ç³»çµ±

3. **Phase 3 - é€²éšåŠŸèƒ½** (Week 5-6)
   - [ ] æ¨¡çµ„2: è³‡æ–™æ¸…æ´—å™¨
   - [ ] æ¨¡çµ„4: å“¡å·¥æŸ¥è©¢

4. **Phase 4 - AI æ•´åˆ** (Week 7)
   - [ ] æ¨¡çµ„5: è³‡æ ¼æª¢æ ¸å™¨
   - [ ] core/ai_client.py

5. **Phase 5 - è‡ªå‹•åŒ–** (Week 8)
   - [ ] æ¨¡çµ„3: æµç¨‹ç¯„æœ¬ç³»çµ±
   - [ ] æ•´åˆæ¸¬è©¦ & å„ªåŒ–

---

## 9. æ¸¬è©¦è³‡æ–™éœ€æ±‚

è«‹åƒè¦‹ `tests/test_data/` ç›®éŒ„ä¸‹çš„æ¸¬è©¦ Excel æª”æ¡ˆï¼š
- `test_m1_*.xlsx` - å ±è¡¨åˆä½µæ¸¬è©¦è³‡æ–™
- `test_m2_*.xlsx` - è³‡æ–™æ¸…æ´—æ¸¬è©¦è³‡æ–™
- `test_m3_*.xlsx` - æµç¨‹ç¯„æœ¬æ¸¬è©¦è³‡æ–™
- `test_m4_*.xlsx` - å“¡å·¥æŸ¥è©¢æ¸¬è©¦è³‡æ–™
- `test_m5_*.xlsx` - è³‡æ ¼æª¢æ ¸æ¸¬è©¦è³‡æ–™
- `test_m6_*.xlsx` - åˆ°æœŸæé†’æ¸¬è©¦è³‡æ–™

---

**æ–‡ä»¶çµæŸ**
